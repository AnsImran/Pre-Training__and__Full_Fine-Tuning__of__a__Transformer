{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35b129e1-b835-48a4-8379-545da9d7f73c",
   "metadata": {
    "id": "35b129e1-b835-48a4-8379-545da9d7f73c"
   },
   "source": [
    "# Pretraining + Full FineTuning an Encoder-Decoder Transformer - PyTorch Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804a3741-bea6-4eb9-b083-d78f3f78748b",
   "metadata": {
    "id": "804a3741-bea6-4eb9-b083-d78f3f78748b"
   },
   "source": [
    "### Links for the datasets used in this notebook: [Pretraining - C4 Dataset](https://github.com/Ariyanbgd/T5_Q-A) AND [Finetuning - SQuaD 2.0 Dataset](https://huggingface.co/datasets/rajpurkar/squad_v2/tree/main)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb20e1d-454a-4e54-9747-debfcc0cd21a",
   "metadata": {
    "id": "ebb20e1d-454a-4e54-9747-debfcc0cd21a"
   },
   "source": [
    "# Question Answering\n",
    "\n",
    "In this notebook we'll explore question answering. We'll implement the \"Text to Text Transfer from Transformers\" (better known as T5). Since we'have implemented transformers from scratch previously ([Transformer from Scratch](https://github.com/AnsImran/Transformer_from_Scratch_for_Text_Summarization/tree/master)) we'll now be able to use them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61427e9-1126-4a62-88e1-c28a8eb06a14",
   "metadata": {
    "id": "a61427e9-1126-4a62-88e1-c28a8eb06a14"
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "### Overview  \n",
    "### Importing the Packages  \n",
    "### Prepare the data for pretraining T5  \n",
    "#### Pre-Training Objective  \n",
    "#### C4 Dataset  \n",
    "#### Process C4  \n",
    "#### Decode to Natural Language  \n",
    "#### Tokenizing and Masking  \n",
    "#### Exercise - tokenize_and_mask  \n",
    "#### Creating the Pairs  \n",
    "### Pretrain a T5 model using C4  \n",
    "#### Instantiate a new transformer model  \n",
    "#### C4 pretraining  \n",
    "### Fine tune the T5 model for Question Answering  \n",
    "#### Creating a list of paired question and answers  \n",
    "#### Exercise - Parse the SQuaD 2.0 dataset  \n",
    "#### Fine tune the T5 model  \n",
    "#### Implement your Question Answering model  \n",
    "#### Exercise - Implement the question answering function  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99ddb72-214d-4671-83d9-ae0ba48bcaa1",
   "metadata": {
    "id": "a99ddb72-214d-4671-83d9-ae0ba48bcaa1"
   },
   "source": [
    "# Overview\n",
    "\n",
    "Due to memory constraints of this environment and for the sake of time, our model will be trained with small datasets, so we won't get models that we could use in production but we'll gain the necessary knowledge about how the Generative Language models are trained and used. Also we won't spend too much time with the architecture of the model (we already created this model from Scratch, see: [Transformer from Scratch](https://github.com/AnsImran/Transformer_from_Scratch_for_Text_Summarization)) but you will instead take a model that is pre-trained on a larger dataset and fine tune it to get better results.\n",
    "\n",
    "In this lab we'll do following:\n",
    "* Understand how the C4 dataset is structured.\n",
    "* Pretrain a transformer model using a Masked Language Model.\n",
    "* Understand how the \"Text to Text Transfer from Transformers\" or T5 model works.\n",
    "* Fine tune the T5 model for Question answering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b57c50-2f4f-4600-82e8-1ae75cce9310",
   "metadata": {
    "id": "a4b57c50-2f4f-4600-82e8-1ae75cce9310"
   },
   "source": [
    "# Importing the Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2142295-a65e-4686-a47b-9d4a0e1a4172",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1743250514750,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "e2142295-a65e-4686-a47b-9d4a0e1a4172"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import log_softmax\n",
    "\n",
    "device_ = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "\n",
    "import string\n",
    "import itertools\n",
    "import transformer_utils\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import textwrap\n",
    "wrapper = textwrap.TextWrapper(width=70)\n",
    "\n",
    "import json\n",
    "\n",
    "from termcolor import colored\n",
    "\n",
    "import sentencepiece as spm\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "2d28f8ed-8e4c-42c2-af4d-ee21bd5b25e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1743250514765,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "2d28f8ed-8e4c-42c2-af4d-ee21bd5b25e9",
    "outputId": "c97c060e-c489-43f2-d258-dc2f2335e05d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "INvLYcBifzUL",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1743250514768,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "INvLYcBifzUL"
   },
   "outputs": [],
   "source": [
    "# Connecting with google drive\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# import os\n",
    "\n",
    "# # Define a path inside your Google Drive\n",
    "# SAVE_PATH = '/content/drive/MyDrive/model_checkpoints'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "F0a-UD-rdA-F",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1743250514784,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "F0a-UD-rdA-F"
   },
   "outputs": [],
   "source": [
    "# Unzipping Tokenizer Model\n",
    "# !unzip data.zip\n",
    "# !unzip models.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbff56bb-1caf-49e7-b30f-b7b36f62d95f",
   "metadata": {},
   "source": [
    "# **Pre-Training Section**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02ef172-e068-4786-8ac6-d33089767edd",
   "metadata": {
    "id": "f02ef172-e068-4786-8ac6-d33089767edd"
   },
   "source": [
    "# Dataprocessing for Pre-Training\n",
    "\n",
    "## Pre-Training Objective\n",
    "\n",
    "In the initial phase of training a T5 model for a Question Answering task, the pre-training process involves leveraging a masked language model (MLM) on a very large dataset, such as the C4 dataset. The objective is to allow the model to learn contextualized representations of words and phrases, fostering a deeper understanding of language semantics. To initiate pre-training, it is essential to employ the Transformer architecture, which forms the backbone of T5. The Transformer's self-attention mechanism enables the model to weigh different parts of the input sequence dynamically, capturing long-range dependencies effectively.\n",
    "\n",
    "Before delving into pre-training, thorough data preprocessing is crucial. The C4 dataset, a diverse and extensive collection of web pages, provides a rich source for language understanding tasks. The dataset needs to be tokenized into smaller units, such as subwords or words, to facilitate model input. Additionally, the text is often segmented into fixed-length sequences or batches, optimizing computational efficiency during training.\n",
    "\n",
    "For the masked language modeling objective, a percentage of the tokenized input is randomly masked, and the model is trained to predict the original content of these masked tokens. This process encourages the T5 model to grasp contextual relationships between words and phrases, enhancing its ability to generate coherent and contextually appropriate responses during downstream tasks like question answering.\n",
    "\n",
    "In summary, the pre-training of the T5 model involves utilizing the Transformer architecture on a sizable dataset like C4, coupled with meticulous data preprocessing to convert raw text into a format suitable for training. The incorporation of a masked language modeling objective ensures that the model learns robust contextual representations, laying a solid foundation for subsequent fine-tuning on specific tasks such as question answering.\n",
    "\n",
    "**Note:** The word \"mask\" will be used throughout this assignment in context of hiding/removing word(s)\n",
    "\n",
    "We'll be implementing the Masked language model (MLM) as shown in the following image.\n",
    "\n",
    "<img src = \"images/loss.png\" width=\"600\" height = \"400\">\n",
    "\n",
    "Assume you have the following text: <span style = \"color:blue\"> **Thank you <span style = \"color:red\">for inviting </span> me to your party <span style = \"color:red\">last</span>  week** </span>\n",
    "\n",
    "\n",
    "Now as input we'll mask the words in red in the text:\n",
    "\n",
    "<span style = \"color:blue\"> **Input:**</span> Thank you  **X** me to your party **Y** week.\n",
    "\n",
    "<span style = \"color:blue\">**Output:**</span> The model should predict the words(s) for **X** and **Y**.\n",
    "\n",
    "**[EOS]** will be used to mark the end of the target sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cf2e16-7950-4cae-8e49-afaed9a5c2ff",
   "metadata": {
    "id": "b1cf2e16-7950-4cae-8e49-afaed9a5c2ff"
   },
   "source": [
    "## C4 Dataset Description\n",
    "\n",
    "The [C4 dataset](https://www.tensorflow.org/datasets/catalog/c4), also known as the Common Crawl C4 (Common Crawl Corpus C4), is a large-scale dataset of web pages collected by the [Common Crawl organization](https://commoncrawl.org/). It is commonly used for various natural language processing tasks and machine learning research. Each sample in the C4 dataset follows a consistent format, making it suitable for pretraining models like BERT. Here's a short explanation and description of the C4 dataset:\n",
    "\n",
    "- Format: Each sample in the C4 dataset is represented as a JSON object, containing several key-value pairs.\n",
    "\n",
    "- Content: The 'text' field in each sample contains the actual text content extracted from web pages. This text often includes a wide range of topics and writing styles, making it diverse and suitable for training language models.\n",
    "\n",
    "- Metadata: The dataset includes metadata such as 'content-length,' 'content-type,' 'timestamp,' and 'url,' providing additional information about each web page. 'Content-length' specifies the length of the content, 'content-type' describes the type of content (e.g., 'text/plain'), 'timestamp' indicates when the web page was crawled, and 'url' provides the source URL of the web page.\n",
    "\n",
    "- Applications: The C4 dataset is commonly used for training and fine-tuning large-scale language models, such as BERT. It serves as a valuable resource for tasks like text classification, named entity recognition, question answering, and more.\n",
    "\n",
    "- Size: The C4 dataset is containing more than 800 GiB of text data, making it suitable for training models with billions of parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85258734-ae47-45ea-9184-f7594e12a664",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc9311df-0873-4e75-a07c-f5b64468da0b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 136,
     "status": "ok",
     "timestamp": 1743250514932,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "dc9311df-0873-4e75-a07c-f5b64468da0b",
    "outputId": "87a62928-d4cf-4085-9dad-6556aeb63d66",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example number 1: \n",
      "\n",
      "{'text': 'Beginners BBQ Class Taking Place in Missoula!\\nDo you want to get better at making delicious BBQ? You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. He will be teaching a beginner level class for everyone who wants to get better with their culinary skills.\\nHe will teach you everything you need to know to compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat selection and trimming, plus smoker and fire information.\\nThe cost to be in the class is $35 per person, and for spectators it is free. Included in the cost will be either a t-shirt or apron and you will be tasting samples of each meat that is prepared.'} \n",
      "\n",
      "example number 2: \n",
      "\n",
      "{'text': 'Discussion in \\'Mac OS X Lion (10.7)\\' started by axboi87, Jan 20, 2012.\\nI\\'ve got a 500gb internal drive and a 240gb SSD.\\nWhen trying to restore using disk utility i\\'m given the error \"Not enough space on disk ____ to restore\"\\nBut I shouldn\\'t have to do that!!!\\nAny ideas or workarounds before resorting to the above?\\nUse Carbon Copy Cloner to copy one drive to the other. I\\'ve done this several times going from larger HDD to smaller SSD and I wound up with a bootable SSD drive. One step you have to remember not to skip is to use Disk Utility to partition the SSD as GUID partition scheme HFS+ before doing the clone. If it came Apple Partition Scheme, even if you let CCC do the clone, the resulting drive won\\'t be bootable. CCC usually works in \"file mode\" and it can easily copy a larger drive (that\\'s mostly empty) onto a smaller drive. If you tell CCC to clone a drive you did NOT boot from, it can work in block copy mode where the destination drive must be the same size or larger than the drive you are cloning from (if I recall).\\nI\\'ve actually done this somehow on Disk Utility several times (booting from a different drive (or even the dvd) so not running disk utility from the drive your cloning) and had it work just fine from larger to smaller bootable clone. Definitely format the drive cloning to first, as bootable Apple etc..\\nThanks for pointing this out. My only experience using DU to go larger to smaller was when I was trying to make a Lion install stick and I was unable to restore InstallESD.dmg to a 4 GB USB stick but of course the reason that wouldn\\'t fit is there was slightly more than 4 GB of data.'} \n",
      "\n",
      "example number 3: \n",
      "\n",
      "{'text': 'Foil plaid lycra and spandex shortall with metallic slinky insets. Attached metallic elastic belt with O-ring. Headband included. Great hip hop or jazz dance costume. Made in the USA.'} \n",
      "\n",
      "example number 4: \n",
      "\n",
      "{'text': \"How many backlinks per day for new site?\\nDiscussion in 'Black Hat SEO' started by Omoplata, Dec 3, 2010.\\n1) for a newly created site, what's the max # backlinks per day I should do to be safe?\\n2) how long do I have to let my site age before I can start making more blinks?\\nI did about 6000 forum profiles every 24 hours for 10 days for one of my sites which had a brand new domain.\\nThere is three backlinks for every of these forum profile so thats 18 000 backlinks every 24 hours and nothing happened in terms of being penalized or sandboxed. This is now maybe 3 months ago and the site is ranking on first page for a lot of my targeted keywords.\\nbuild more you can in starting but do manual submission and not spammy type means manual + relevant to the post.. then after 1 month you can make a big blast..\\nWow, dude, you built 18k backlinks a day on a brand new site? How quickly did you rank up? What kind of competition/searches did those keywords have?\"} \n",
      "\n",
      "example number 5: \n",
      "\n",
      "{'text': 'The Denver Board of Education opened the 2017-18 school year with an update on projects that include new construction, upgrades, heat mitigation and quality learning environments.\\nWe are excited that Denver students will be the beneficiaries of a four year, $572 million General Obligation Bond. Since the passage of the bond, our construction team has worked to schedule the projects over the four-year term of the bond.\\nDenver voters on Tuesday approved bond and mill funding measures for students in Denver Public Schools, agreeing to invest $572 million in bond funding to build and improve schools and $56.6 million in operating dollars to support proven initiatives, such as early literacy.\\nDenver voters say yes to bond and mill levy funding support for DPS students and schools. Click to learn more about the details of the voter-approved bond measure.\\nDenver voters on Nov. 8 approved bond and mill funding measures for DPS students and schools. Learn more about what’s included in the mill levy measure.'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load example jsons\n",
    "with open('data/c4-en-10k.jsonl', 'r') as file:\n",
    "    example_jsons = [json.loads(line.strip()) for line in file]\n",
    "\n",
    "# Printing the examples to see how the data looks like\n",
    "for i in range(5):\n",
    "    print(f'example number {i+1}: \\n\\n{example_jsons[i]} \\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94be9c6b-ae0f-4fcc-9c75-cb9b0d3ebf66",
   "metadata": {
    "id": "94be9c6b-ae0f-4fcc-9c75-cb9b0d3ebf66"
   },
   "source": [
    "## Processing C4 Dataset\n",
    "\n",
    "For the purpose of pretaining the T5 model, we'll only use the `content` of each entry. In the following code, we filter only the field `text` from all the entries in the dataset. This is the data that we'll use to create the `inputs` and `targets` of our language model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9725ef43-68da-41e8-9add-f495b9f2601f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1743250514935,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "9725ef43-68da-41e8-9add-f495b9f2601f",
    "outputId": "7f747441-9383-42f4-dd8e-fc1e92b6d0be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginners BBQ Class Taking Place in Missoula!\n",
      "Do you want to get better at making delicious BBQ? You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. He will be teaching a beginner level class for everyone who wants to get better with their culinary skills.\n",
      "He will teach you everything you need to know to compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat selection and trimming, plus smoker and fire information.\n",
      "The cost to be in the class is $35 per person, and for spectators it is free. Included in the cost will be either a t-shirt or apron and you will be tasting samples of each meat that is prepared.\n"
     ]
    }
   ],
   "source": [
    "# Grab text field from dictionary\n",
    "natural_language_texts = [example_json['text'] for example_json in example_jsons]\n",
    "\n",
    "# Print the first text example\n",
    "print(natural_language_texts[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78675370-6cc9-4f77-b546-ad238de07280",
   "metadata": {
    "id": "78675370-6cc9-4f77-b546-ad238de07280"
   },
   "source": [
    "### Decoding to Natural Language - Loading Pretrained Tokenizer\n",
    "\n",
    "\n",
    "The [SentencePieceTokenizer](https://www.tensorflow.org/text/api_docs/python/text/SentencepieceTokenizer), used in the code snippet, tokenizes text into subword units, enhancing handling of complex word structures, out-of-vocabulary words, and multilingual support. It simplifies preprocessing, ensures consistent tokenization, and seamlessly integrates with machine learning frameworks.\n",
    "\n",
    "In this task, a SentencePiece model is loaded from a file, which is used to tokenize text into subwords represented by integer IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccca0e61-dfa0-4242-aae8-f9bfdfbd4429",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 92,
     "status": "ok",
     "timestamp": 1743250515022,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "ccca0e61-dfa0-4242-aae8-f9bfdfbd4429",
    "outputId": "17b90fa3-0e0e-452a-b243-cd3ddcf9ad1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 19, 3, 9, 3106, 1499, 5]\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "# Load the SentencePiece model\n",
    "tokenizer = spm.SentencePieceProcessor()\n",
    "tokenizer.load('./models/sentencepiece.model')\n",
    "\n",
    "# Tokenize text using the loaded model\n",
    "text = \"This is a sample text.\"\n",
    "tokenized_text = tokenizer.encode(text, out_type=int)  # Use out_type=int to get int token ids | out_type, torch.tensor kar k daikhna, otherwise integer bhi thek hi hay\n",
    "\n",
    "print(tokenized_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8f2c89-8223-43eb-8bfb-eb4149202a2e",
   "metadata": {
    "id": "7b8f2c89-8223-43eb-8bfb-eb4149202a2e"
   },
   "source": [
    "In this tokenizer the string `</s>` is used as `EOS` token. By default, the tokenizer does not add the `EOS` to the end of each sentence, so we need to add it manually when required. Let's verify what id correspond to this token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3224741-0162-4ac5-a947-945dfe09d935",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1743250515028,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "c3224741-0162-4ac5-a947-945dfe09d935",
    "outputId": "1a78d334-af97-4843-c703-90bceae3574c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS: 1\n"
     ]
    }
   ],
   "source": [
    "eos = tokenizer.piece_to_id(\"</s>\")\n",
    "print(\"EOS:\", eos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ddf54c4-9e8f-49f3-a883-d67e9bbd06b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1743250515071,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "1ddf54c4-9e8f-49f3-a883-d67e9bbd06b8",
    "outputId": "fbe68ac0-17b8-4438-ae0e-d74c1427a62b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word\t\t-->\tTokenization\n",
      "\n",
      "Foil\t-->\t[4452, 173]\n",
      "plaid\t-->\t[30772]\n",
      "lycra\t-->\t[3, 120, 2935]\n",
      "and\t-->\t[11]\n",
      "spandex\t-->\t[8438, 26, 994]\n",
      "shortall\t-->\t[710, 1748]\n",
      "with\t-->\t[28]\n",
      "metallic\t-->\t[18813]\n",
      "slinky\t-->\t[3, 7, 4907, 63]\n",
      "insets.\t-->\t[16, 2244, 7, 5]\n",
      "Attached\t-->\t[28416, 15, 26]\n",
      "metallic\t-->\t[18813]\n",
      "elastic\t-->\t[15855]\n",
      "belt\t-->\t[6782]\n",
      "with\t-->\t[28]\n",
      "O-ring.\t-->\t[411, 18, 1007, 5]\n",
      "Headband\t-->\t[3642, 3348]\n",
      "included.\t-->\t[1285, 5]\n",
      "Great\t-->\t[1651]\n",
      "hip\t-->\t[5436]\n",
      "hop\t-->\t[13652]\n",
      "or\t-->\t[42]\n",
      "jazz\t-->\t[9948]\n",
      "dance\t-->\t[2595]\n",
      "costume.\t-->\t[11594, 5]\n",
      "Made\t-->\t[6465]\n",
      "in\t-->\t[16]\n",
      "the\t-->\t[8]\n",
      "USA.\t-->\t[2312, 5]\n"
     ]
    }
   ],
   "source": [
    "# printing the encoding of each word to see how subwords are tokenized\n",
    "tokenized_text = [(tokenizer.encode(word, out_type=int), word) for word in natural_language_texts[2].split()]\n",
    "\n",
    "print(\"Word\\t\\t-->\\tTokenization\\n\")\n",
    "for tokens, word in tokenized_text:\n",
    "    print(f\"{word}\\t-->\\t{tokens}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171f883d-9d9a-47c9-b7cb-24ee751d728c",
   "metadata": {},
   "source": [
    "# Skip the following cells until you reach the one labeled \"skip_end!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e992543-a2da-4d12-bc03-98b23e808ec7",
   "metadata": {
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1743250515132,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "6e992543-a2da-4d12-bc03-98b23e808ec7"
   },
   "outputs": [],
   "source": [
    "###################################################################################################################\n",
    "# The cells enclosed within ##### **** ##### can be skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c04ef70b-7677-4f47-97b1-1143a1c8a077",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1743250515158,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "c04ef70b-7677-4f47-97b1-1143a1c8a077",
    "outputId": "96f3982c-eaf2-415f-e65c-92d45d9e76b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirming kengthof data sets\n",
    "len(natural_language_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64f747ef-7230-441a-b987-3b66dbfe4cb0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1743250515164,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "64f747ef-7230-441a-b987-3b66dbfe4cb0",
    "outputId": "1bf90b1c-ae62-4a00-95c7-d3a4f2845a40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Foil', 'plaid', 'lycra', 'and', 'spandex', 'shortall', 'with', 'metallic', 'slinky', 'insets.', 'Attached', 'metallic', 'elastic', 'belt', 'with', 'O-ring.', 'Headband', 'included.', 'Great', 'hip', 'hop', 'or', 'jazz', 'dance', 'costume.', 'Made', 'in', 'the', 'USA.']\n"
     ]
    }
   ],
   "source": [
    "# loooking at some words in the dataset text\n",
    "print(natural_language_texts[2].split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4d84797-f8e4-45db-aeb0-1a81de5e4719",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1743250515209,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "e4d84797-f8e4-45db-aeb0-1a81de5e4719",
    "outputId": "c4d72cef-a2ec-4c5a-8a30-b3d539c57cfd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30772]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizinga word\n",
    "tokenizer.tokenize('plaid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d81caa6e-72aa-4545-99fb-46ed0ea8a1b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1743250515223,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "d81caa6e-72aa-4545-99fb-46ed0ea8a1b6",
    "outputId": "f51a36d6-7db0-48b4-b375-f409a9941881"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 120, 2935]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizing another word\n",
    "tokenizer.tokenize('lycra')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2038588d-f864-4a4b-b987-cb2c485b414f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1743250515232,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "2038588d-f864-4a4b-b987-cb2c485b414f",
    "outputId": "baae027f-7f91-4f49-e3e7-3f60135316cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('lycra', '')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decoding / detokenizing \n",
    "tokenizer.decode([120, 2935]), tokenizer.detokenize([3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8704194d-2195-4095-b8b3-e97e0010017a",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1743250515235,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "8704194d-2195-4095-b8b3-e97e0010017a"
   },
   "outputs": [],
   "source": [
    "###################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c44bf07-f6d5-4413-afde-87e60d5ae90c",
   "metadata": {},
   "source": [
    "# skip_end!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c3437c-6427-4954-8da5-b7dad5d35113",
   "metadata": {
    "id": "25c3437c-6427-4954-8da5-b7dad5d35113"
   },
   "source": [
    "And as usual, the library provides a function to turn numeric tokens into human readable text. Look how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c6774df-d14c-42c0-bdfc-77aefa67d730",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1743250515250,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "3c6774df-d14c-42c0-bdfc-77aefa67d730",
    "outputId": "8911d693-3cbf-4fb6-f3b4-a3808bf5fb58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized: [12847, 277]\n",
      "detokenized: Beginners\n"
     ]
    }
   ],
   "source": [
    "# We can see that detokenize successfully undoes the tokenization\n",
    "print(f\"tokenized: {tokenizer.tokenize('Beginners')}\\ndetokenized: {tokenizer.detokenize(tokenizer.tokenize('Beginners'))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ea975b-beb1-4a94-a0fa-26484eff8a8f",
   "metadata": {
    "id": "68ea975b-beb1-4a94-a0fa-26484eff8a8f"
   },
   "source": [
    "As we can see above, we were able to take a piece of string and tokenize it.\n",
    "\n",
    "Now we'll create `input` and `target` pairs that will allow us to train our model. T5 uses the ids at the end of the vocab file as sentinels. For example, it will replace:\n",
    "   - `vocab_size - 1` by `<Z>`\n",
    "   - `vocab_size - 2` by `<Y>`\n",
    "   - and so forth.\n",
    "   \n",
    "It assigns every word a `chr`.\n",
    "\n",
    "The `pretty_decode` function below, which we'll use in a bit, helps in handling the type when decoding.\n",
    "\n",
    "\n",
    "Notice that:\n",
    "```python\n",
    "string.ascii_letters = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "```\n",
    "\n",
    "**NOTE:** Targets may have more than the 52 sentinels we replace, but this is just to get an idea of things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e619817-f69d-419d-b6c2-9d55ff6f8bc7",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1743250515253,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "0e619817-f69d-419d-b6c2-9d55ff6f8bc7"
   },
   "outputs": [],
   "source": [
    "def get_sentinels(tokenizer, display=False):\n",
    "    sentinels  = {}\n",
    "    vocab_size = tokenizer.vocab_size()\n",
    "    \n",
    "    for i, char in enumerate(reversed(string.ascii_letters), 1):\n",
    "        decoded_text = tokenizer.detokenize([vocab_size - i])\n",
    "\n",
    "        # Sentinels, ex: <Z> - <a>\n",
    "        sentinels[decoded_text] = f'<{char}>'\n",
    "\n",
    "        if display:\n",
    "            print(f'The sentinel is <{char}> and the decoded token is:', decoded_text)\n",
    "\n",
    "    return sentinels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf6cbab-4e49-4149-a9cb-38aa66e1e968",
   "metadata": {},
   "source": [
    "# Skip the following cells until you reach the one labeled \"skip_end!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0865620e-d103-42c1-86bf-7592ed064fff",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1743250515257,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "0865620e-d103-42c1-86bf-7592ed064fff"
   },
   "outputs": [],
   "source": [
    "###################################################################################################################\n",
    "# The cells enclosed within ##### **** ##### can be skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1532d2dc-4838-4850-bac9-242b2ce0a8a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1743250515262,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "1532d2dc-4838-4850-bac9-242b2ce0a8a4",
    "outputId": "d272e765-d413-423c-a712-cf3e94e1dfb3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.ascii_letters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52863536-f6f2-4bb4-8ba9-08693c69427e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1743250515283,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "52863536-f6f2-4bb4-8ba9-08693c69427e",
    "outputId": "3f1dd921-0d65-4181-f0ed-072649ed0b6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<reversed at 0x794dae9d47f0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return a reverse iterator over the values of the given sequence.\n",
    "reversed('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f57ea7d-d9b0-4a37-b4a5-5a6093c1ac8f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1743250515295,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "8f57ea7d-d9b0-4a37-b4a5-5a6093c1ac8f",
    "outputId": "f68552df-8f60-442f-9753-ec187d80862f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, char in enumerate(reversed('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'), 1):\n",
    "    print('i: ',i, '\\tchar: ', char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c9587bb2-173c-42d1-8ef7-640fef90a768",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1743250515316,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "c9587bb2-173c-42d1-8ef7-640fef90a768",
    "outputId": "5be7ecc8-ee43-4c8a-93c0-b68316353fda"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirming vocab size\n",
    "tokenizer.vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "17937856-3725-45b2-a4ce-06558f7a85e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1743250515332,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "17937856-3725-45b2-a4ce-06558f7a85e9",
    "outputId": "b88afaa4-1d7f-4a3d-d0c7-16d8d31aeecf"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Internațional'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exploring tokens\n",
    "tokenizer.detokenize([32000 - 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "46e8e92b-aa5b-4c53-9c2f-a5908424e170",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1743250515342,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "46e8e92b-aa5b-4c53-9c2f-a5908424e170"
   },
   "outputs": [],
   "source": [
    "#############################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b3d123-cd51-4f6a-814c-8be753875704",
   "metadata": {},
   "source": [
    "# skip_end!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c73bfc6-5beb-441d-a9f9-0bea4bbb93d7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1743250515359,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "6c73bfc6-5beb-441d-a9f9-0bea4bbb93d7",
    "outputId": "5c869c70-61ef-4b31-c600-c255f80a9b30",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentinels = get_sentinels(tokenizer, display=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4795e004-52a7-4a85-88ce-de85dea1f1a4",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1743250515364,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "4795e004-52a7-4a85-88ce-de85dea1f1a4"
   },
   "outputs": [],
   "source": [
    "def pretty_decode(encoded_str_list, sentinels, tokenizer):\n",
    "    # If it's already a string, just replace sentinel tokens with their mapped characters\n",
    "    if isinstance(encoded_str_list, str):\n",
    "        for token, char in sentinels.items():\n",
    "            encoded_str_list = encoded_str_list.replace(token, char)\n",
    "        return encoded_str_list\n",
    "\n",
    "    # If it's a list of token IDs, decode and then apply replacements\n",
    "    decoded_str = tokenizer.detokenize(encoded_str_list)\n",
    "    for token, char in sentinels.items():\n",
    "        decoded_str = decoded_str.replace(token, char)\n",
    "    return decoded_str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b22a6c-fab6-4799-8c13-47815a337c5c",
   "metadata": {
    "id": "e3b22a6c-fab6-4799-8c13-47815a337c5c"
   },
   "source": [
    "Now, let's use the `pretty_decode` function in the following sentence. Note that all the words listed as sentinels, will be replaced by the function with the corresponding sentinel. It could be a drawback of this method, but don't worry about it now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b1b58fe4-a5de-4799-ace1-ff2cfe56e955",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1743250515374,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "b1b58fe4-a5de-4799-ace1-ff2cfe56e955",
    "outputId": "37339128-84f8-45f0-9090-44fd24b3da22"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'I want to dress up as an <V> this <b>.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example usage\n",
    "pretty_decode(\"I want to dress up as an Intellectual this halloween.\", sentinels, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9dfbadd6-b02e-44b1-af51-538dce043663",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1743250515378,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "9dfbadd6-b02e-44b1-af51-538dce043663"
   },
   "outputs": [],
   "source": [
    "##################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11998bc2-eaf8-4844-88bf-4ed87a5efb53",
   "metadata": {
    "id": "11998bc2-eaf8-4844-88bf-4ed87a5efb53"
   },
   "source": [
    "The functions above make our `inputs` and `targets` more readable. For example, we might see something like this once we implement the masking function below.\n",
    "\n",
    "- <span style=\"color:red\"> Input sentence: </span> Younes and Lukasz were working together in the lab yesterday after lunch.\n",
    "- <span style=\"color:red\">Input: </span> Younes and Lukasz  **Z** together in the **Y** yesterday after lunch.\n",
    "- <span style=\"color:red\">Target: </span> **Z** were working **Y** lab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5af63a2-7e78-4b2e-a61b-c9ed15b3261c",
   "metadata": {
    "id": "f5af63a2-7e78-4b2e-a61b-c9ed15b3261c"
   },
   "source": [
    "### Tokenizing and Masking - Masked Language Modelling\n",
    "\n",
    "In this task, we'll implement the `tokenize_and_mask` function, which tokenizes and masks input words based on a given probability. The probability is controlled by the `noise` parameter, typically set to mask around `15%` of the words in the input text. The function will generate two lists of tokenized sequences following the algorithm outlined below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b778aa2-1f92-45d9-9867-76051448f501",
   "metadata": {
    "id": "0b778aa2-1f92-45d9-9867-76051448f501"
   },
   "source": [
    "#### tokenize_and_mask\n",
    "\n",
    "- Start with two empty lists: `inps` and `targs`\n",
    "- Tokenize the input text using the given tokenizer.\n",
    "- For each `token` in the tokenized sequence:\n",
    "  - Generate a random number(simulating a weighted coin toss)\n",
    "  - If the random value is greater than the given threshold(noise):\n",
    "    - Add the current token to the `inps` list\n",
    "  - Else:\n",
    "    - If a new sentinel must be included(read note **):\n",
    "      - Compute the next sentinel ID using a progression.\n",
    "      - Add a sentinel into the `inps` and `targs` to mark the position of the masked element.\n",
    "    - Add the current token to the `targs` list.\n",
    "\n",
    "** There's a special case to consider. If two consecutive tokens get masked during the process, you don't need to add a new sentinel to the sequences. To account for this, use the `prev_no_mask` flag, which starts as `True` but is turned to `False` each time you mask a new element. The code that adds sentinels will only be executed if, before masking the token, the flag was in the `True` state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d420fcd3-2cf9-4ca8-8b65-f7f0ce4ea09e",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1743250515410,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "d420fcd3-2cf9-4ca8-8b65-f7f0ce4ea09e"
   },
   "outputs": [],
   "source": [
    "def tokenize_and_mask(text,\n",
    "                      noise =0.15,\n",
    "                      randomizer=np.random.uniform,\n",
    "                      tokenizer=None):\n",
    "    \"\"\"Tokenizes and masks a given input.\n",
    "\n",
    "    Args:\n",
    "        text (str or bytes): Text input.\n",
    "        noise (float, optional): Probability of masking a token. Defaults to 0.15.\n",
    "        randomizer (function, optional): Function that generates random values. Defaults to np.random.uniform.\n",
    "        tokenizer (function, optional): Tokenizer function. Defaults to tokenize.\n",
    "\n",
    "    Returns:\n",
    "        inps, targs: Lists of integers associated to inputs and targets.\n",
    "    \"\"\"\n",
    "\n",
    "    # Current sentinel number (starts at 0)\n",
    "    cur_sentinel_num = 0\n",
    "\n",
    "    # Inputs and targets\n",
    "    inps, targs = [], []\n",
    "\n",
    "    # Vocab_size\n",
    "    vocab_size = int(tokenizer.vocab_size())\n",
    "\n",
    "    # EOS token id\n",
    "    # Must be at the end of each target!\n",
    "    eos = tokenizer.piece_to_id(\"</s>\")\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # prev_no_mask is True if the previous token was NOT masked, False otherwise\n",
    "    # set prev_no_mask to True\n",
    "    prev_no_mask = True\n",
    "\n",
    "    # Loop over the tokenized text\n",
    "    for token in tokenizer.encode(text, out_type=int):\n",
    "\n",
    "        # Generate a random value between 0 and 1\n",
    "        rnd_val = randomizer()\n",
    "\n",
    "        # Check if the noise is greater than a random value (weighted coin flip)\n",
    "        if rnd_val < noise:\n",
    "\n",
    "            # Check if previous token was NOT masked\n",
    "            if prev_no_mask:\n",
    "\n",
    "                # Current sentinel increases by 1\n",
    "                cur_sentinel_num += 1\n",
    "\n",
    "                # Compute end_id by subtracting current sentinel value out of the total vocabulary size\n",
    "                end_id = vocab_size - cur_sentinel_num\n",
    "\n",
    "                # Append end_id at the end of the targets\n",
    "                targs.append(end_id)\n",
    "\n",
    "                # Append end_id at the end of the inputs\n",
    "                inps.append(end_id)\n",
    "\n",
    "            # Append token at the end of the targets\n",
    "            targs.append(token)\n",
    "\n",
    "            # set prev_no_mask accordingly\n",
    "            prev_no_mask = False\n",
    "\n",
    "        else:\n",
    "\n",
    "            # Append token at the end of the inputs\n",
    "            inps.append(token)\n",
    "\n",
    "            # Set prev_no_mask accordingly\n",
    "            prev_no_mask = True\n",
    "\n",
    "\n",
    "    # Add EOS token to the end of the targets\n",
    "    targs.append(eos)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return inps, targs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e2d50b19-9f5e-41c9-8f9a-9e0264b86b1e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1743250515429,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "e2d50b19-9f5e-41c9-8f9a-9e0264b86b1e",
    "outputId": "db5b9207-870b-466c-a8b5-e59c27875a30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized inputs - shape=53:\n",
      "\n",
      "[31999, 15068, 4501, 3, 12297, 3399, 16, 5964, 7115, 31998, 531, 25, 241, 12, 129, 394, 44, 492, 31997, 58, 148, 56, 43, 8, 1004, 6, 474, 31996, 39, 4793, 230, 5, 2721, 6, 1600, 1630, 31995, 1150, 4501, 15068, 16127, 6, 9137, 2659, 5595, 31994, 782, 3624, 14627, 15, 12612, 277, 5]\n",
      "\n",
      "targets - shape=19:\n",
      "\n",
      "[31999, 12847, 277, 31998, 9, 55, 31997, 3326, 15068, 31996, 48, 30, 31995, 727, 1715, 31994, 45, 301, 1]\n"
     ]
    }
   ],
   "source": [
    "# Some logic to mock a np.random value generator\n",
    "# Needs to be in the same cell for it to always generate same output\n",
    "def testing_rnd():\n",
    "    def dummy_generator():\n",
    "        vals        = np.linspace(0, 1, 10)\n",
    "        cyclic_vals = itertools.cycle(vals)\n",
    "        for _ in range(100):\n",
    "            yield next(cyclic_vals)\n",
    "\n",
    "    dumr = itertools.cycle(dummy_generator())\n",
    "\n",
    "    def dummy_randomizer():\n",
    "        return next(dumr)\n",
    "\n",
    "    return dummy_randomizer\n",
    "\n",
    "input_str = 'Beginners BBQ Class Taking Place in Missoula!\\nDo you want to get better at making delicious BBQ? You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers.'\n",
    "\n",
    "inps, targs = tokenize_and_mask(input_str, randomizer=testing_rnd(), tokenizer=tokenizer)\n",
    "print(f\"tokenized inputs - shape={len(inps)}:\\n\\n{inps}\\n\\ntargets - shape={len(targs)}:\\n\\n{targs}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3ed43e-c9fb-483e-b051-a68bd0010082",
   "metadata": {
    "id": "1f3ed43e-c9fb-483e-b051-a68bd0010082"
   },
   "source": [
    "We'll now use the inputs and the targets from the `tokenize_and_mask` function we implemented above. Let's look at the decoded version of our masked sentence using your `inps` and `targs` from the sentence above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7f1557a0-92cd-470d-845e-b903cb04750d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1743250515435,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "7f1557a0-92cd-470d-845e-b903cb04750d",
    "outputId": "ebf97caf-5249-4f57-b9c1-a772735cc9c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: \n",
      "\n",
      " <Z> BBQ Class Taking Place in Missoul <Y> Do you want to get better at making <X>? You will have the opportunity, put <W> your calendar now. Thursday, September 22 <V> World Class BBQ Champion, Tony Balay <U>onestar Smoke Rangers.\n",
      "\n",
      "Targets: \n",
      "\n",
      " <Z> Beginners <Y>a! <X> delicious BBQ <W> this on <V>nd join <U> from L\n"
     ]
    }
   ],
   "source": [
    "print('Inputs: \\n\\n', pretty_decode(inps, sentinels, tokenizer))\n",
    "print('\\nTargets: \\n\\n', pretty_decode(targs, sentinels, tokenizer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0698cd9-a55a-4e6a-8b37-36fa71db2340",
   "metadata": {
    "id": "d0698cd9-a55a-4e6a-8b37-36fa71db2340"
   },
   "source": [
    "### Creating input-target Pairs\n",
    "\n",
    "We'll now create pairs using our dataset. We'll iterate over your data and create (inp, targ) pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0ca6e5e7-e585-4a45-b9f2-43dacf81b9f4",
   "metadata": {
    "executionInfo": {
     "elapsed": 17228,
     "status": "ok",
     "timestamp": 1743250532664,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "0ca6e5e7-e585-4a45-b9f2-43dacf81b9f4"
   },
   "outputs": [],
   "source": [
    "# Apply tokenize_and_mask\n",
    "inputs_targets_pairs = [tokenize_and_mask(text.encode('utf-8', errors='ignore').decode('utf-8'), tokenizer=tokenizer)\n",
    "                        for text in natural_language_texts]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3c1d00-ef0c-42b6-8b7e-8b3a1298a623",
   "metadata": {},
   "source": [
    "# Skip the following cells until you reach the one labeled \"skip_end!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f795a5a-f3b2-4055-83e0-e368490f45c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9a6109f7-d032-4641-8d72-9ed1de41020f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1743250532710,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "9a6109f7-d032-4641-8d72-9ed1de41020f",
    "outputId": "d7101757-be2d-4fa0-826b-adc1d2cdfaaf"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Pencarian FILM Untuk \"Peace Breaker 2017\"\\nyuk mampir ke channel say..\\nEdges East provides the l..\\nA corrupt cop makes one w..\\nPeace Breaker 2017 ~ 破�..\\nNáo Loạn - Peace Break..\\nPlease subscribe and hit ..\\nuploaded in HD at http://..\\nI cannot believe I manage..'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at a typical text bodyin our dataset\n",
    "natural_language_texts[10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ac80e338-2c7f-4def-b967-8c45661ce807",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1743250532729,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "ac80e338-2c7f-4def-b967-8c45661ce807",
    "outputId": "0eed41cd-5da8-4395-a0a9-b33c38d3d7e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Pencarian FILM Untuk \"Peace Breaker 2017\"\\nyuk mampir ke channel say..\\nEdges East provides the l..\\nA corrupt cop makes one w..\\nPeace Breaker 2017 ~ \\xe7\\xa0\\xb4\\xef\\xbf\\xbd..\\nN\\xc3\\xa1o Lo\\xe1\\xba\\xa1n - Peace Break..\\nPlease subscribe and hit ..\\nuploaded in HD at http://..\\nI cannot believe I manage..'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "natural_language_texts[10].encode('utf-8', errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d14f836d-82f7-4ba3-97da-d6430b97e4ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1743250532734,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "d14f836d-82f7-4ba3-97da-d6430b97e4ee",
    "outputId": "ea63c490-1119-445d-d905-5f825bb31685"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Pencarian FILM Untuk \"Peace Breaker 2017\"\\nyuk mampir ke channel say..\\nEdges East provides the l..\\nA corrupt cop makes one w..\\nPeace Breaker 2017 ~ 破�..\\nNáo Loạn - Peace Break..\\nPlease subscribe and hit ..\\nuploaded in HD at http://..\\nI cannot believe I manage..'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "natural_language_texts[10].encode('utf-8', errors='ignore').decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "26aea9b3-9f19-47af-83db-3eca8f2dc968",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1743250532750,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "26aea9b3-9f19-47af-83db-3eca8f2dc968"
   },
   "outputs": [],
   "source": [
    "################################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da4dcad-996a-4e01-a91c-d77fa0dc6805",
   "metadata": {},
   "source": [
    "# skip_end!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb0476f-9a25-4192-a683-b59bbb177d94",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1743250532759,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "1eb0476f-9a25-4192-a683-b59bbb177d94",
    "outputId": "538317a0-9f51-4798-ba99-14d0c9ce5cd2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def display_input_target_pairs(inputs_targets_pairs, sentinels, wrapper=textwrap.TextWrapper(width=70), tokenizer=None):\n",
    "    for i, inp_tgt_pair in enumerate(inputs_targets_pairs, 1):\n",
    "        inps, tgts = inp_tgt_pair\n",
    "\n",
    "        # Directly decode the token ID lists to strings\n",
    "        decoded_inps = pretty_decode(inps, sentinels, tokenizer)\n",
    "        decoded_tgts = pretty_decode(tgts, sentinels, tokenizer)\n",
    "\n",
    "        print(f'[{i}]\\n\\n'\n",
    "              f'inputs:\\n{wrapper.fill(text=decoded_inps)}\\n\\n'\n",
    "              f'targets:\\n{wrapper.fill(text=decoded_tgts)}\\n\\n\\n')\n",
    "\n",
    "\n",
    "# Print the first 5 samples\n",
    "display_input_target_pairs(inputs_targets_pairs[0:5], sentinels, wrapper, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5629005-81bb-4bf8-a4ee-9bfb55f4acb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4765130f-5932-484a-a707-8b44a02a43fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c8e8a4d-c378-495c-8d0b-5cdac0ceb25c",
   "metadata": {
    "id": "2c8e8a4d-c378-495c-8d0b-5cdac0ceb25c"
   },
   "source": [
    "# **Pretraining Section - Part-2**\n",
    "\n",
    "Now we are going to use the Transformer's architecture that we coded previously [Transformer_from_Scratch](https://github.com/AnsImran/Transformer_from_Scratch_for_Text_Summarization) to summarize text, but this time to answer questions. Instead of training the question answering model from scratch, we'll first \"pre-train\" the model using the C4 data set we just processed. This will help the model to learn the general structure of language from a large dataset. This is much easier to do, as we don't need to label any data, but just use the masking, which is done automatically. We'll will then use the data from the SQuAD 2.0 dataset to teach the model to answer questions given a context. To start let's review the Transformer's architecture.\n",
    "\n",
    "<img src = \"images/fulltransformer.png\" width=\"300\" height=\"600\">\n",
    "\n",
    "\n",
    "\n",
    "## Instantiating a New Transformer Model\n",
    "\n",
    "The code implemented in the previous week have been packaged into the `transformer_utils.py` file. We can import it here, and setup with the same configuration used there.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c22f2e9-d6f0-4177-9d3d-03a5380bd48b",
   "metadata": {
    "executionInfo": {
     "elapsed": 100,
     "status": "ok",
     "timestamp": 1743250532861,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "1c22f2e9-d6f0-4177-9d3d-03a5380bd48b"
   },
   "outputs": [],
   "source": [
    "# Define the model parameters\n",
    "num_layers                 = 2\n",
    "embedding_dim              = 128\n",
    "fully_connected_dim        = 128\n",
    "num_heads                  = 2\n",
    "positional_encoding_length = 256\n",
    "\n",
    "encoder_vocab_size = int(tokenizer.vocab_size())\n",
    "decoder_vocab_size = encoder_vocab_size\n",
    "\n",
    "# Initialize the model\n",
    "transformer = transformer_utils.Transformer(\n",
    "                                                num_layers,\n",
    "                                                embedding_dim,\n",
    "                                                num_heads,\n",
    "                                                fully_connected_dim,\n",
    "                                                encoder_vocab_size,\n",
    "                                                decoder_vocab_size,\n",
    "                                                positional_encoding_length,\n",
    "                                                positional_encoding_length,\n",
    "                                            )\n",
    "\n",
    "device_ = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa70c868-e281-4381-9c59-90ff1712cf4e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1743250532902,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "fa70c868-e281-4381-9c59-90ff1712cf4e",
    "outputId": "272d0c13-54bc-433b-8dfe-f98350e0aa94",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(32000, 128, padding_idx=0)\n",
       "    (enc_layers): ModuleList(\n",
       "      (0-1): 2 x EncoderLayer(\n",
       "        (attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (layernorm1): BatchNorm1d(128, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (layernorm2): BatchNorm1d(128, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(32000, 128, padding_idx=0)\n",
       "    (dec_layers): ModuleList(\n",
       "      (0-1): 2 x DecoderLayer(\n",
       "        (mha1): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (mha2): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (layernorm1): BatchNorm1d(128, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (layernorm2): BatchNorm1d(128, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (layernorm3): BatchNorm1d(128, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_ffn): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (final_layer): Linear(in_features=128, out_features=32000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our architecture\n",
    "transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97660dd-cadf-4749-b360-079cd2534a22",
   "metadata": {
    "id": "f97660dd-cadf-4749-b360-079cd2534a22"
   },
   "source": [
    "\n",
    "Now, you will define the optimizer and the loss function. For this task the model will try to predict the masked words, so, as in the previous lab, the loss function will be the `torch.NLLLoss(...)`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2f0c11-12f9-43ab-b9a2-88d022a53a2a",
   "metadata": {
    "id": "8c2f0c11-12f9-43ab-b9a2-88d022a53a2a"
   },
   "source": [
    "## Setting Up Dataloader\n",
    "\n",
    "For training a PyTorch model we need to arrange the data into dataset and dataloader. Now, we'll get the `inputs` and the `targets` for the transformer model from the `inputs_targets_pairs`. Before creating the dataset, you need to be sure that all `inputs` have the same length by truncating the longer sequences and padding the shorter ones with `0`. The same must be done for the targets.\n",
    "\n",
    "We'll use a `BATCH_SIZE = 64`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34be5643-440c-44b0-aaa6-4336f9d33acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "encoder_maxlen = 150\n",
    "decoder_maxlen = 50\n",
    "BATCH_SIZE     = 512\n",
    "num_epochs     = 40\n",
    "\n",
    "\n",
    "# Mock: inputs_targets_pairs = [...] # list of (input_seq, target_seq)\n",
    "# Make sure it's defined before running this.\n",
    "\n",
    "# Split inputs and targets\n",
    "input_seqs  = [x[0] for x in inputs_targets_pairs]\n",
    "target_seqs = [x[1] for x in inputs_targets_pairs]\n",
    "\n",
    "# Pad sequences\n",
    "def pad_sequences(sequences, maxlen, pad_value=0):\n",
    "    return np.array([\n",
    "        seq[:maxlen] + [pad_value] * max(0, maxlen - len(seq))\n",
    "        for seq in sequences\n",
    "    ])\n",
    "\n",
    "inputs  = pad_sequences(input_seqs, encoder_maxlen)\n",
    "targets = pad_sequences(target_seqs, decoder_maxlen)\n",
    "\n",
    "# Convert to tensors\n",
    "inputs_tensor  = tensor(inputs, dtype=torch.long)\n",
    "targets_tensor = tensor(targets, dtype=torch.long)\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = TensorDataset(inputs_tensor, targets_tensor)\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=2  # Tune this depending on your CPU\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11aa1d8-ff0c-4761-bb55-0043909e5b74",
   "metadata": {},
   "source": [
    "# Skip the following cells until you reach the one labeled \"skip_end!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3c7f512c-a540-453b-949b-3654f78ec009",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1743250532905,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "3c7f512c-a540-453b-949b-3654f78ec009"
   },
   "outputs": [],
   "source": [
    "# ignore this cell\n",
    "# torch.cuda.empty_cache()\n",
    "# torch.cuda.reset_peak_memory_stats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "72cfb9c4-1c45-48d2-992d-c04f765b4bb6",
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1743250533133,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "72cfb9c4-1c45-48d2-992d-c04f765b4bb6"
   },
   "outputs": [],
   "source": [
    "####################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a9d39317-3471-41d9-9116-422d3a7ada2d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1743250533181,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "a9d39317-3471-41d9-9116-422d3a7ada2d",
    "outputId": "8e1bbfe5-fe43-434a-c5fa-9730c8387ab4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 150]) torch.Size([64, 50])\n"
     ]
    }
   ],
   "source": [
    "# ignore this cell\n",
    "# testing dataloader\n",
    "for x, y in dataloader:\n",
    "    print(x.shape, y.shape)  # Should print [64, 150] and [64, 50]\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b2793b59-daf4-4b69-88b3-1a667992d689",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1743250533202,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "b2793b59-daf4-4b69-88b3-1a667992d689",
    "outputId": "4b270f0e-4fb5-4ef5-e46e-75f8a16ab46d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ignore this cell\n",
    "len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "866f7a0e-1737-4432-85e5-d02fcaf3f283",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3003,
     "status": "ok",
     "timestamp": 1743250536395,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "866f7a0e-1737-4432-85e5-d02fcaf3f283",
    "outputId": "ef3a26ad-777d-480a-c892-3d6cbf145a5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:  torch.Size([64, 50, 32000])\n"
     ]
    }
   ],
   "source": [
    "# ignore this cell\n",
    "# Inspecting predictions shape\n",
    "transformer.to(device)\n",
    "preds, _ = transformer(inp, tar)\n",
    "print('preds: ', preds.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0aff93dc-61ed-41ab-849c-62c0a3c40d4f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2419,
     "status": "ok",
     "timestamp": 1743250538816,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "0aff93dc-61ed-41ab-849c-62c0a3c40d4f",
    "outputId": "e82f1802-474e-4e82-ac06-8fb186c35b76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:  torch.Size([3200, 32000])\n",
      "targets:  torch.Size([3200])\n",
      "10.636120796203613\n"
     ]
    }
   ],
   "source": [
    "# ignore this cell\n",
    "# testing with optimizer and loss function\n",
    "criterion = nn.NLLLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(transformer.parameters(), lr=0.001)\n",
    "\n",
    "# Ensure outputs is of type Float\n",
    "outputs = preds.float().clone()\n",
    "outputs = outputs.reshape(-1, preds.shape[2])\n",
    "print('outputs: ', outputs.shape)\n",
    "\n",
    "# Ensure targets is of type Long\n",
    "targets = tar\n",
    "targets = targets.reshape(-1)\n",
    "print('targets: ', targets.shape)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Calculate loss\n",
    "loss = criterion(outputs, targets)\n",
    "loss.backward()\n",
    "\n",
    "print(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fc1726d3-2737-4825-8ac1-ac0c72b18bfb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1743250538834,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "fc1726d3-2737-4825-8ac1-ac0c72b18bfb",
    "outputId": "18b83a51-db09-49b3-beb2-58843a4cd762"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[31999,   549, 31998,  ..., 31979,  8160, 31978],\n",
       "        [31999,    46, 31998,  ...,   268, 31979,    19],\n",
       "        [31999,     7, 31998,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [31999,   242, 31998,  ...,     0,     0,     0],\n",
       "        [31999,   208, 31998,  ..., 31977,    63, 31976],\n",
       "        [31999,  1609,     3,  ...,     0,     0,     0]], device='cuda:0')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ignore this cell\n",
    "tar[:, :-1] # tar_inp |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a5386d0d-c688-44d3-baf1-e492725085aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1743250538852,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "a5386d0d-c688-44d3-baf1-e492725085aa",
    "outputId": "af3d1d0e-2c21-4fed-ec65-45f6c980592d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  549, 31998,  9537,  ...,  8160, 31978,  6708],\n",
       "        [   46, 31998,    25,  ..., 31979,    19, 31978],\n",
       "        [    7, 31998, 26306,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  242, 31998,    49,  ...,     0,     0,     0],\n",
       "        [  208, 31998, 29077,  ...,    63, 31976,  9754],\n",
       "        [ 1609,     3, 31998,  ...,     0,     0,     0]], device='cuda:0')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ignore this cell\n",
    "tar[:, 1:] # tar_real | to loss fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "88f97a78-7208-4d6e-8083-0ef0b287f51f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1743250538915,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "88f97a78-7208-4d6e-8083-0ef0b287f51f",
    "outputId": "4c3b4457-c1e9-425a-a5f5-8e2806ee1426"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([31999, 22735,  1820, 31998,    33,  6470,    12,  2467,    69,  3718,\n",
       "         1476,  4677,  1213, 31997,    13,   334,   847,  1684,    44,     3,\n",
       "        18735,  6366,    44,     8,  1166, 31996,  3227,  2904,  4466,   137,\n",
       "        17173,  1820, 31995,  1338, 31994,    36,  1213,    16,  1718,    11,\n",
       "         1660,     6,   383,     8,  2578,     3,   184, 15740,  9088,     7,\n",
       "            7,     5,   332, 22684, 20344, 18206,  1820,    71,   372,  2634,\n",
       "           56,    36,  2098, 31993, 23096,  2028,    78,    24,    62,   164,\n",
       "        31992,  1338,    44,   489,  2028,     5,   863,   391,     5,   134,\n",
       "            5,   553,     5,   345,     5,    12,  2753,  1741, 31991,    17,\n",
       "            5,  1677,     3,    99,    25,   515,    12,  2467,    78, 31990,\n",
       "           54,   766,    62,    43,   631,   542,    21,     8,   372,  2634,\n",
       "            5,  4083, 13961, 22492,  3430,     3, 31989, 24596,   283, 26418,\n",
       "         2365,  5568,  2853,  4305, 17116,  4677,  1522,    36,  1213,    30,\n",
       "            8,   511,  2721,    13,   334,   847,    44,     3, 18735,     3,\n",
       "          102,     5, 31988,     5,     6,     3,  3227,   224,   239, 31987],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ignore this cell\n",
    "inp[0,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "22bdbe69-92b2-45ea-9e68-b8b0da6d6034",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1743250538935,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "22bdbe69-92b2-45ea-9e68-b8b0da6d6034",
    "outputId": "268959a1-4bc9-452d-d8cd-92a8056dcbd2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'InternaționalHEN | erwachsene are encouraged to attend our monthly board meetings held Cushion of every month starting at 7:00 pm at the Center imunitarunless otherwise noted). NOTE | Intellectual meeting traditi be held in July and August, during the Director & Volunteer recess. TEAM DINNER | A team dinner will be served disguise 6:30pm so that we mayexerce meeting at 7pm. Please R.S.V.P. to president@nourishet.org if you plan to attend so predominant can ensure we have enough food for the team dinner. REGULAR AND amitiéUAL MEETING Section 4.02 Regular meetings shall be held on the second Thursday of every month at 7:00 p. erkennt., unless such daydimension'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ignore this cell\n",
    "inp_de = inp[0, :].to('cpu').clone().numpy()\n",
    "inp_de = tokenizer.detokenize(inp_de.tolist())\n",
    "inp_de\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "168b43fc-e776-4e86-922c-f117afcaa1be",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1743250538937,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "168b43fc-e776-4e86-922c-f117afcaa1be",
    "outputId": "303c38e5-a2c8-4316-e36c-d861f40c686a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([31999,   549, 31998,  9537, 31997,    30,     8,   511,  2721, 31996,\n",
       "           41, 31995,   465, 31994,    56, 31993,    44, 31992,   456,     8,\n",
       "        31991,  9361,     7, 31990,    62, 31989, 21478, 31988,    51, 31987,\n",
       "         7250, 31986,  1522, 31985,  1781, 31984,   416, 31983,     5, 31982,\n",
       "          284, 31981,   215, 31980,     8,  7389, 31979,  8160, 31978,  6708],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ignore this cell\n",
    "tar[0,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0f01cae1-b39a-4d3f-be17-50c3a6ac0e60",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1743250538943,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "0f01cae1-b39a-4d3f-be17-50c3a6ac0e60",
    "outputId": "e7ece985-1d31-4c7f-eb69-b162a383dd68"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Internațional W erwachsene Members Cushion on the second Thursday imunitar ( Intellectual No traditi will disguise atexerce start thenourisheidess predominant weamitiéANN erkenntmdimension falls inférieur shall refugi hour cheddar next unterlieg. garanteaz eachfăcute yearréglage the Annual pedepse electedGermain Corporation'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ignore this cell\n",
    "tar_de = tar[0, :].to('cpu').clone().numpy()\n",
    "tar_de = tokenizer.detokenize(tar_de.tolist())\n",
    "tar_de\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c9dfa755-07b6-4101-9a1c-c0a2ccf815f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1743250538950,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "c9dfa755-07b6-4101-9a1c-c0a2ccf815f7",
    "outputId": "66f98359-4d47-43d8-86c6-b1756b189c53"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<Z>HEN | <Y> are encouraged to attend our monthly board meetings held <X> of every month starting at 7:00 pm at the Center <W>unless otherwise noted). NOTE | <V> meeting <U> be held in July and August, during the Director & Volunteer recess. TEAM DINNER | A team dinner will be served <T> 6:30pm so that we may<S> meeting at 7pm. Please R.S.V.P. to president@<R>t.org if you plan to attend so <Q> can ensure we have enough food for the team dinner. REGULAR AND <P>UAL MEETING Section 4.02 Regular meetings shall be held on the second Thursday of every month at 7:00 p. <O>., unless such day<N>'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ignore this cell\n",
    "pretty_decode(inp_de, sentinels, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "584952c5-e63e-434b-9119-2804fcb046d0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1743250538954,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "584952c5-e63e-434b-9119-2804fcb046d0",
    "outputId": "0060f3b6-e59b-4dda-e8a0-3b60ca677662"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<Z> W <Y> Members <X> on the second Thursday <W> ( <V> No <U> will <T> at<S> start the<R>idess <Q> we<P>ANN <O>m<N> falls <M> shall <L> hour <K> next <J>. <I> each<H> year<G> the Annual <F> elected<E> Corporation'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ignore this cell\n",
    "pretty_decode(tar_de, sentinels, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7b759456-9a97-45c5-a5e3-c4ef2fb036cc",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1743250538958,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "7b759456-9a97-45c5-a5e3-c4ef2fb036cc"
   },
   "outputs": [],
   "source": [
    "########################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1637d9a-716d-49d8-af56-4f1259cf03eb",
   "metadata": {},
   "source": [
    "# skip_end!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999fab93-dc71-4b54-9879-1c2140c5d5be",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df6c67c-9d24-4155-aa21-b780f9888bfb",
   "metadata": {},
   "source": [
    "Now, we can run the training loop for 10 epochs. Running it with a big dataset such as C4 on a good computer with enough memory and a good GPU could take more than 24 hours. Here, you will run few epochs using a small portion of the C4 dataset for illustration. It will only take a few minutes, but the model won't be very powerful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cf3ddaab-5df8-4b2c-b525-5261b4e326b9",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1743250539174,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "cf3ddaab-5df8-4b2c-b525-5261b4e326b9"
   },
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "from torch import device, tensor\n",
    "from torch.nn import NLLLoss\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import time\n",
    "from torch.amp import GradScaler, autocast\n",
    "from torch import save\n",
    "\n",
    "# Set device\n",
    "device_ = device('cuda' if cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# checkpoint = torch.load('./drive/MyDrive/model_checkpoints/checkpoint_epoch_15.pt', map_location=device_)\n",
    "# transformer.load_state_dict(checkpoint['model_state_dict'])\n",
    "# transformer.eval()  # Optional: set to eval mode if you're doing inference\n",
    "\n",
    "\n",
    "learning_rate  = 1e-3\n",
    "pad_idx        = 0\n",
    "\n",
    "\n",
    "# Define model, criterion, optimizer\n",
    "# transformer = YourTransformerModel(...) # Define or import your model\n",
    "transformer.to(device_)\n",
    "\n",
    "criterion = nn.NLLLoss(ignore_index=pad_idx)\n",
    "optimizer = AdamW(transformer.parameters(), lr=learning_rate)\n",
    "scaler    = GradScaler()  # For mixed precision\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'\\nEpoch [{epoch + 1}/{num_epochs}]')\n",
    "    start_time = time.time()\n",
    "\n",
    "    transformer.train()\n",
    "    running_loss = 0\n",
    "\n",
    "    for batch_idx, (inp, tar) in enumerate(dataloader):\n",
    "        inp = inp.to(device_, non_blocking=True)\n",
    "        tar = tar.to(device_, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast(device_type=device_.type):\n",
    "\n",
    "            # 'tar'       right shifted by adding 31999 token in the begining of each tar sequence\n",
    "            # 'targets'   and by removing the first token from targets | overall same effect\n",
    "            preds, _ = transformer(inp, tar[:, :-1])\n",
    "            outputs  = preds.reshape(-1, preds.shape[2])\n",
    "            targets  = tar[:, 1:].reshape(-1)\n",
    "            loss     = criterion(outputs, targets)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(transformer.parameters(), max_norm=1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        avg_loss = running_loss / (batch_idx + 1)\n",
    "\n",
    "        if (batch_idx + 1) % 20 == 0:\n",
    "            print(f\"[Batch {batch_idx + 1}/{len(dataloader)}] Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    epoch_time = time.time() - start_time\n",
    "    print(f\"Epoch Time: {epoch_time:.2f}s | Average Loss: {avg_loss:.4f}\")\n",
    "    save({'model_state_dict': transformer.state_dict()}, f'checkpoint_epoch_{epoch+1}.pt')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c7f5857c-6a73-43e3-b6fc-9a96d11f9eec",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1743250539179,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "c7f5857c-6a73-43e3-b6fc-9a96d11f9eec"
   },
   "outputs": [],
   "source": [
    "# # model saving and loading code\n",
    "\n",
    "# import torch\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "# torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "\n",
    "# torch.save({\n",
    "#     'epoch': epoch,\n",
    "#     'model_state_dict': transformer.state_dict(),\n",
    "#     'optimizer_state_dict': optimizer.state_dict(),\n",
    "#     'scaler_state_dict': scaler.state_dict(),  # If using AMP\n",
    "#     'loss': avg_loss\n",
    "# }, os.path.join(SAVE_PATH, f'checkpoint_epoch_{epoch+1}.pt'))\n",
    "\n",
    "\n",
    "# checkpoint = torch.load('your checkpoint', map_location=device_)\n",
    "\n",
    "# transformer.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# scaler.load_state_dict(checkpoint['scaler_state_dict'])  # Only if you're using AMP\n",
    "\n",
    "# start_epoch = checkpoint['epoch'] + 1\n",
    "# transformer.to(device_)\n",
    "# transformer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b6a83f-e072-44e5-87a2-e87011351a28",
   "metadata": {},
   "source": [
    "# Skip the following cells until you reach the one labeled \"skip_end!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30985f28-70ee-4df8-b93d-ed4b0c5dee62",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106e2c02-e3d7-4267-bed1-5530cbd88469",
   "metadata": {
    "id": "106e2c02-e3d7-4267-bed1-5530cbd88469"
   },
   "source": [
    "#### Checking model's inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "335d1508-e399-4ba9-8ade-91e84733425c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1917,
     "status": "ok",
     "timestamp": 1743254624773,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "335d1508-e399-4ba9-8ade-91e84733425c",
    "outputId": "a20ff9eb-ea2e-42ef-b4a1-c35aa24ba1c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from torch import load\n",
    "# from torch import device, tensor\n",
    "# device_ = device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# path = SAVE_PATH + '/pretrain checkpoint_epoch_15.pt'\n",
    "\n",
    "# checkpoint = load(path, map_location=device_, weights_only=True)\n",
    "# transformer.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed8837c-fda5-4d95-b5a7-832cd3f3348a",
   "metadata": {
    "id": "7ed8837c-fda5-4d95-b5a7-832cd3f3348a",
    "outputId": "a00795a3-c747-48f4-8476-33467c9a6c66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    3,  8691,    16,     8,   842,    13, 27874,   896,  2969,     6,\n",
       "           69,  1487,    18,  4905,  6432,    19,     3, 20690, 31999,    45,\n",
       "         1012,  8548, 10108,     6, 31998,  2698,  6411,  1384,    11,  1651,\n",
       "         7488,  7120, 31997,  1651,  2309,     6,  3661,     6,  5441, 15754,\n",
       "            7,    11,   452,  1855,   931,    33,   269,    30,     8, 26929,\n",
       "        31996,   492,    69, 27874,   896,  2969,  1128,     8,  1523,  1247,\n",
       "           21, 31995,   384,    42,   268,  1469, 31994,   421,  1595,    19,\n",
       "         1772,   204, 31993,  8538, 31992,  2801,    28,   305,   941,  2542,\n",
       "           11,  1338,  2801,     5,    37,  4983,    32,    26,   397, 27874,\n",
       "           19,  1069,    16,     8,   842,    13, 31991,     5,    37,  2062,\n",
       "         1983, 31990,  3885,     7, 31989,  8382,    16,     8, 31988,    13,\n",
       "        31987, 15916,  2893,     6, 27874,     5,    71,   775,     3,    31,\n",
       "        31986,  2237,    31,   785, 31985,     8,   182, 31984,    13, 27874,\n",
       "            5,   262, 31983,  4666,    19,     8,   167, 31982,    11,   167,\n",
       "         8732,    13,     8,  3661,    16,     8, 12738,    15,     7,  4833],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c345873-e363-4e1f-832c-04b1bcfc52c8",
   "metadata": {
    "id": "8c345873-e363-4e1f-832c-04b1bcfc52c8",
    "outputId": "ccd5282e-eeb0-4219-b21d-9673300729d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([31999,  8382,   676, 31998,     8, 31997,     5, 31996,     6, 31995,\n",
       "          136, 31994,     5, 31993,  4118, 31992, 20680, 31991, 27874,   690,\n",
       "        31990,   106,    11, 31989,    19, 31988,   842, 31987,     8, 31986,\n",
       "         9124, 31985,    16, 31984,  2050, 31983,  4629, 31982,  1310,  2946,\n",
       "        31981,  1212, 31980,    49,    30, 31979,     3, 31978,   298,   464],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar[2,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0823cbcc-3498-4c78-9cb7-94604218576f",
   "metadata": {
    "id": "0823cbcc-3498-4c78-9cb7-94604218576f",
    "outputId": "5b5eb665-8fea-494b-f451-5ba1cda73d03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Located in the heart of Belfast City Centre, our budget-friendly accommodation is ideally Internațional from popular tourist attractions, erwachsene Grand Opera House and Great Victoria Square Cushion Great shopping, restaurants, historic landmarks and public transport options are right on the doorstep imunitar making our Belfast City Centre location the ideal base for Intellectual family or business trip traditi Our hotel is offering 2 disguise beautifullyexerce rooms with 5 modern conference and meeting rooms. The Travelodge Belfast is located in the heart ofnourishe. The restaurant Act predominant Sonsamitié situated in the erkennt ofdimension linen quarter, Belfast. A unique ' inférieur led' property refugi the very cheddar of Belfast. E unterliegIC is the most garanteaz and most sophisticated of the restaurants in the Deanes portfolio\""
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_de = tokenizer.detokenize(inp[2,:].tolist())\n",
    "\n",
    "inp_de\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6901f0c-e94d-4659-a26a-2d1770e4818c",
   "metadata": {
    "id": "b6901f0c-e94d-4659-a26a-2d1770e4818c",
    "outputId": "ab920bb3-7520-4a07-aefa-f6860de86bae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Located in the heart of Belfast City Centre, our budget-friendly accommodation is ideally <Z> from popular tourist attractions, <Y> Grand Opera House and Great Victoria Square <X> Great shopping, restaurants, historic landmarks and public transport options are right on the doorstep <W> making our Belfast City Centre location the ideal base for <V> family or business trip <U> Our hotel is offering 2 <T> beautifully<S> rooms with 5 modern conference and meeting rooms. The Travelodge Belfast is located in the heart of<R>. The restaurant Act <Q> Sons<P> situated in the <O> of<N> linen quarter, Belfast. A unique ' <M> led' property <L> the very <K> of Belfast. E <J>IC is the most <I> and most sophisticated of the restaurants in the Deanes portfolio\""
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretty_decode(inp_de, sentinels, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4208753-5a15-4675-9026-d450de620e29",
   "metadata": {
    "id": "e4208753-5a15-4675-9026-d450de620e29",
    "outputId": "5d398d99-8b16-4beb-b246-46e07f09da83"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Internațional situated minutes erwachsene the Cushion. imunitar, Intellectual any traditi. disguise37exerce furnishednourishe Belfast city predominanton andamitié is erkennt heartdimension the inférieurdesign refugi in cheddar centre unterliegIP garanteaz recently openedfăcute Meréglageer on pedepse Germain while working'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar_de = tokenizer.detokenize(tar[2,:].tolist())\n",
    "tar_de\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eed0457-3e00-44e5-b82d-e9b0fb578a1f",
   "metadata": {
    "id": "0eed0457-3e00-44e5-b82d-e9b0fb578a1f",
    "outputId": "0878115a-59ba-4358-e8e7-ad3fcbad72cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<Z> situated minutes <Y> the <X>. <W>, <V> any <U>. <T>37<S> furnished<R> Belfast city <Q>on and<P> is <O> heart<N> the <M>design <L> in <K> centre <J>IP <I> recently opened<H> Me<G>er on <F> <E> while working'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretty_decode(tar_de, sentinels, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c996a6-67c3-468b-9afb-c125bc28c34e",
   "metadata": {
    "id": "b9c996a6-67c3-468b-9afb-c125bc28c34e"
   },
   "outputs": [],
   "source": [
    "##########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8891140-c637-4bce-9589-ac9c0ec53928",
   "metadata": {
    "id": "d8891140-c637-4bce-9589-ac9c0ec53928"
   },
   "outputs": [],
   "source": [
    "transformer.eval()\n",
    "preds, _ = transformer(inp[2:4,:], tar[2:4,:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac720c2-d6ee-4605-8f0c-b1d12c2d00cb",
   "metadata": {
    "id": "fac720c2-d6ee-4605-8f0c-b1d12c2d00cb",
    "outputId": "be5f0cd2-21e7-4718-de64-e5956180f360"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 49, 32000])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938f668a-9f5b-44d8-a6e7-2d1458fc0b14",
   "metadata": {
    "id": "938f668a-9f5b-44d8-a6e7-2d1458fc0b14",
    "outputId": "918b16a2-61d7-49d9-c8f1-29e8cd7094bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4983, 31998, 31998,  8548, 31997,  8548, 31996,  8548, 31995,  5441,\n",
       "         31994,     8, 31993,  4983,  2801,  4983, 31991,  8538, 31990, 31990,\n",
       "          2801, 31989, 31989,  4983, 31988,  2698, 31987,   628, 31986,  4983,\n",
       "         31985,  4983, 31984,     8, 31983,     8, 31982,  3214, 31981, 31981,\n",
       "          2801, 31980,  4983, 31979, 31979,   628, 31978,  3214, 31977],\n",
       "        [    3, 31998,  7717, 31997, 31997, 31997,     3, 31996, 16959, 31995,\n",
       "             3, 31994,     3, 31993,     3, 31992,     3, 31991, 10503, 31990,\n",
       "            12, 31989,     3, 31988,     3, 31987,     3, 31986,     3, 31985,\n",
       "             3, 31984,     3, 31983,     3, 31982,     3, 31981, 26661, 31980,\n",
       "             3, 31979, 16959, 31978,     3, 31977,     3, 31976,    12]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds2 = torch.argmax(preds, dim=-1)\n",
    "preds2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3baa804-fc40-47ca-aa4c-fc6b30325d6b",
   "metadata": {
    "id": "d3baa804-fc40-47ca-aa4c-fc6b30325d6b",
    "outputId": "b3dbe8d5-4d26-439e-c861-95fff5c3a529"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Travel erwachsene erwachsene tourist Cushion tourist imunitar tourist Intellectual historic traditi the disguise Travel rooms Travelnourishe beautifully predominant predominant roomsamitiéamitié Travel erkennt Granddimension space inférieur Travel refugi Travel cheddar the unterlieg the garanteaz walkingfăcutefăcute roomsréglage Travel pedepse pedepse spaceGermain walkingdistinctly'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_de = tokenizer.detokenize(preds2[0].tolist())\n",
    "\n",
    "inp_de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da18647-295d-420f-b958-1feea1c03142",
   "metadata": {
    "id": "9da18647-295d-420f-b958-1feea1c03142",
    "outputId": "984d83cb-beb1-4150-b023-87c985f13d0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Travel <Y> <Y> tourist <X> tourist <W> tourist <V> historic <U> the <T> Travel rooms Travel<R> beautifully <Q> <Q> rooms<P><P> Travel <O> Grand<N> space <M> Travel <L> Travel <K> the <J> the <I> walking<H><H> rooms<G> Travel <F> <F> space<E> walking<D>'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretty_decode(preds2[0].tolist(), sentinels, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563ac857-850c-4dca-8cb5-d1fe995fad10",
   "metadata": {
    "id": "563ac857-850c-4dca-8cb5-d1fe995fad10"
   },
   "outputs": [],
   "source": [
    "#############################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc98ff7d-2407-4992-b276-0a793855ec83",
   "metadata": {},
   "source": [
    "# skip_end!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbba2f3c-2995-4485-b514-5efa0911258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a50f32c-58bf-4e13-afc9-b40cf2ab96e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bb2e6b-d6fa-403b-9b10-4735c253df5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c33dc7-180d-45d4-91c8-3c16d3692fe7",
   "metadata": {},
   "source": [
    "# **Fine-Tuning Section Part-1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cef9e6-9b69-43ef-adfc-6a4a33de0d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1198bf15-927e-4b4d-b85f-bf37bc90916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63555b84-48e8-425f-8bad-45226dc45b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb58f44a-5eb6-48b7-ae68-1cd8a1bf2d76",
   "metadata": {
    "id": "eb58f44a-5eb6-48b7-ae68-1cd8a1bf2d76"
   },
   "source": [
    "## Loading a pretrained model\n",
    "\n",
    "To show how powerful this model actually is, we trained it for several epochs with the full dataset in Colab and saved the weights for you. We can load them using the cell below. For the rest of the notebook, we'll see the power of the transfer learning in action."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634810da-c93b-4048-aeaf-d101cd71b6fb",
   "metadata": {},
   "source": [
    "### Instantiating model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860211d6-5224-4441-aa46-9446aa4ddca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model parameters\n",
    "num_layers                 = 2\n",
    "embedding_dim              = 128\n",
    "fully_connected_dim        = 128\n",
    "num_heads                  = 2\n",
    "positional_encoding_length = 256\n",
    "\n",
    "encoder_vocab_size = int(tokenizer.vocab_size())\n",
    "decoder_vocab_size = encoder_vocab_size\n",
    "\n",
    "# Initialize the model\n",
    "transformer = transformer_utils.Transformer(\n",
    "    num_layers,\n",
    "    embedding_dim,\n",
    "    num_heads,\n",
    "    fully_connected_dim,\n",
    "    encoder_vocab_size,\n",
    "    decoder_vocab_size,\n",
    "    positional_encoding_length,\n",
    "    positional_encoding_length,\n",
    ")\n",
    "\n",
    "device_ = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "transformer.to(device_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675f4592-6451-4bc7-93b5-0575357698e6",
   "metadata": {},
   "source": [
    "### Loading Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "bafed080-0a11-46c3-864e-367d25fd5837",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1743254602988,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "bafed080-0a11-46c3-864e-367d25fd5837"
   },
   "outputs": [],
   "source": [
    "# from torch import load\n",
    "# from torch import device, tensor\n",
    "# device_ = device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# checkpoint = load('pretrain checkpoint_epoch_15.pt', map_location=device_, weights_only=True)\n",
    "# transformer.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f1b88c-02d4-4021-908f-23ae26a32715",
   "metadata": {
    "id": "e4f1b88c-02d4-4021-908f-23ae26a32715"
   },
   "source": [
    "# Data Processing for Fine-Tuning\n",
    "\n",
    "Now, we are going to fine tune the pretrained model for Question Answering using the [SQUad 2.0 dataset](https://rajpurkar.github.io/SQuAD-explorer/).\n",
    "\n",
    "SQuAD, short for Stanford Question Answering Dataset, is a dataset designed for training and evaluating question answering systems. It consists of real questions posed by humans on a set of Wikipedia articles, where the answer to each question is a specific span of text within the corresponding article.\n",
    "\n",
    "SQuAD 1.1, the previous version of the SQuAD dataset, contains 100,000+ question-answer pairs on about 500 articles.\n",
    "SQuAD 2.0, contains 50.000 additional questions that are not meant to be answered. This extra set of questions can help to train models to detect unanswerable questions.\n",
    "\n",
    "Let's load the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fe2543-4996-4d62-84f3-9c8e91e6207c",
   "metadata": {},
   "source": [
    "## Data Loading - SQuAD 2.0 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2152c67e-fdb8-4f33-aede-c3995427cc52",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1509,
     "status": "ok",
     "timestamp": 1743250604877,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "2152c67e-fdb8-4f33-aede-c3995427cc52",
    "outputId": "e17a1ac9-715f-4d85-c313-3cbd68f36ce8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles: 442\n"
     ]
    }
   ],
   "source": [
    "with open('data/train-v2.0.json', 'r') as f:\n",
    "    example_jsons = json.load(f)\n",
    "\n",
    "example_jsons = example_jsons['data']\n",
    "\n",
    "print('Number of articles: ' + str(len(example_jsons)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab014b6a-af34-4fec-81a4-19b78f691968",
   "metadata": {
    "id": "ab014b6a-af34-4fec-81a4-19b78f691968"
   },
   "source": [
    "The structure of each article is as follows:\n",
    "- `title`: The article title\n",
    "- `paragraphs`: A list of paragraphs and questions related to them\n",
    "    - `context`: The actual paragraph text\n",
    "    - `qas`: A set of question related to the paragraph\n",
    "        - `question`: A question\n",
    "        - `id`: The question unique identifier\n",
    "        - `is_imposible`: Boolean, specifies if the question can be answered or not\n",
    "        - `answers`: A set of possible answers for the question\n",
    "            - `text`: The answer\n",
    "            - `answer_start`: The index of the character that starts the sentence containing the explicit answer to the question\n",
    "            \n",
    "Take a look at an article by running the next cell. Notice that the `context` is usually the last element for every paragraph:           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5c95fc41-3574-4787-8795-358d7177bdc4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1743250607774,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "5c95fc41-3574-4787-8795-358d7177bdc4",
    "outputId": "e6f5ff33-3803-459e-9d28-96dae4b74a90",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Beyoncé\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'qas': [{'question': 'When did Beyonce start becoming popular?',\n",
       "   'id': '56be85543aeaaa14008c9063',\n",
       "   'answers': [{'text': 'in the late 1990s', 'answer_start': 269}],\n",
       "   'is_impossible': False},\n",
       "  {'question': 'What areas did Beyonce compete in when she was growing up?',\n",
       "   'id': '56be85543aeaaa14008c9065',\n",
       "   'answers': [{'text': 'singing and dancing', 'answer_start': 207}],\n",
       "   'is_impossible': False},\n",
       "  {'question': \"When did Beyonce leave Destiny's Child and become a solo singer?\",\n",
       "   'id': '56be85543aeaaa14008c9066',\n",
       "   'answers': [{'text': '2003', 'answer_start': 526}],\n",
       "   'is_impossible': False},\n",
       "  {'question': 'In what city and state did Beyonce  grow up? ',\n",
       "   'id': '56bf6b0f3aeaaa14008c9601',\n",
       "   'answers': [{'text': 'Houston, Texas', 'answer_start': 166}],\n",
       "   'is_impossible': False},\n",
       "  {'question': 'In which decade did Beyonce become famous?',\n",
       "   'id': '56bf6b0f3aeaaa14008c9602',\n",
       "   'answers': [{'text': 'late 1990s', 'answer_start': 276}],\n",
       "   'is_impossible': False},\n",
       "  {'question': 'In what R&B group was she the lead singer?',\n",
       "   'id': '56bf6b0f3aeaaa14008c9603',\n",
       "   'answers': [{'text': \"Destiny's Child\", 'answer_start': 320}],\n",
       "   'is_impossible': False},\n",
       "  {'question': 'What album made her a worldwide known artist?',\n",
       "   'id': '56bf6b0f3aeaaa14008c9604',\n",
       "   'answers': [{'text': 'Dangerously in Love', 'answer_start': 505}],\n",
       "   'is_impossible': False},\n",
       "  {'question': \"Who managed the Destiny's Child group?\",\n",
       "   'id': '56bf6b0f3aeaaa14008c9605',\n",
       "   'answers': [{'text': 'Mathew Knowles', 'answer_start': 360}],\n",
       "   'is_impossible': False},\n",
       "  {'question': 'When did Beyoncé rise to fame?',\n",
       "   'id': '56d43c5f2ccc5a1400d830a9',\n",
       "   'answers': [{'text': 'late 1990s', 'answer_start': 276}],\n",
       "   'is_impossible': False},\n",
       "  {'question': \"What role did Beyoncé have in Destiny's Child?\",\n",
       "   'id': '56d43c5f2ccc5a1400d830aa',\n",
       "   'answers': [{'text': 'lead singer', 'answer_start': 290}],\n",
       "   'is_impossible': False},\n",
       "  {'question': 'What was the first album Beyoncé released as a solo artist?',\n",
       "   'id': '56d43c5f2ccc5a1400d830ab',\n",
       "   'answers': [{'text': 'Dangerously in Love', 'answer_start': 505}],\n",
       "   'is_impossible': False},\n",
       "  {'question': 'When did Beyoncé release Dangerously in Love?',\n",
       "   'id': '56d43c5f2ccc5a1400d830ac',\n",
       "   'answers': [{'text': '2003', 'answer_start': 526}],\n",
       "   'is_impossible': False},\n",
       "  {'question': 'How many Grammy awards did Beyoncé win for her first solo album?',\n",
       "   'id': '56d43c5f2ccc5a1400d830ad',\n",
       "   'answers': [{'text': 'five', 'answer_start': 590}],\n",
       "   'is_impossible': False},\n",
       "  {'question': \"What was Beyoncé's role in Destiny's Child?\",\n",
       "   'id': '56d43ce42ccc5a1400d830b4',\n",
       "   'answers': [{'text': 'lead singer', 'answer_start': 290}],\n",
       "   'is_impossible': False},\n",
       "  {'question': \"What was the name of Beyoncé's first solo album?\",\n",
       "   'id': '56d43ce42ccc5a1400d830b5',\n",
       "   'answers': [{'text': 'Dangerously in Love', 'answer_start': 505}],\n",
       "   'is_impossible': False}],\n",
       " 'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_article = example_jsons[0]\n",
    "example_article\n",
    "\n",
    "print(\"Title: \" + example_article[\"title\"])\n",
    "example_article[\"paragraphs\"][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965f99d8-b526-4ded-921f-79eaec0d8e44",
   "metadata": {
    "id": "965f99d8-b526-4ded-921f-79eaec0d8e44"
   },
   "source": [
    "The previous article might be difficult to navigate so here is a nicely formatted example paragraph:\n",
    "```python\n",
    "{\n",
    "  \"context\": \"Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles 'Crazy in Love' and 'Baby Boy'\",\n",
    "  \"qas\": [\n",
    "    {\n",
    "      \"question\": \"When did Beyonce start becoming popular?\",\n",
    "      \"id\": \"56be85543aeaaa14008c9063\",\n",
    "      \"answers\": [\n",
    "        {\n",
    "          \"text\": \"in the late 1990s\",\n",
    "          \"answer_start\": 269\n",
    "        }\n",
    "      ],\n",
    "      \"is_impossible\": false\n",
    "    },\n",
    "    {\n",
    "      \"question\": \"What areas did Beyonce compete in when she was growing up?\",\n",
    "      \"id\": \"56be85543aeaaa14008c9065\",\n",
    "      \"answers\": [\n",
    "        {\n",
    "          \"text\": \"singing and dancing\",\n",
    "          \"answer_start\": 207\n",
    "        }\n",
    "      ],\n",
    "      \"is_impossible\": false\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcacaf5-4f8f-4720-9cb1-3bfa0f56a507",
   "metadata": {},
   "source": [
    "## Data Pasing - Creating Input-Target Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5b9dd952-60a8-4f12-9328-ed10e2a7aadb",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1743250612413,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "5b9dd952-60a8-4f12-9328-ed10e2a7aadb"
   },
   "outputs": [],
   "source": [
    "def parse_squad(dataset):\n",
    "    \"\"\"Extract all the answers/questions pairs from the SQuAD dataset\n",
    "\n",
    "    Args:\n",
    "        dataset (dict): The imported JSON dataset\n",
    "\n",
    "    Returns:\n",
    "        inputs, targets: Two lists containing the inputs and the targets for the QA model\n",
    "    \"\"\"\n",
    "\n",
    "    inputs, targets = [], []\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Loop over all the articles\n",
    "    for article in dataset:\n",
    "\n",
    "        # Loop over each paragraph of each article\n",
    "        for paragraph in article['paragraphs']:\n",
    "\n",
    "            # Extract context from the paragraph\n",
    "            context = paragraph['context']\n",
    "\n",
    "            #Loop over each question of the given paragraph\n",
    "            for qa in paragraph['qas']:\n",
    "\n",
    "                # If this question is not impossible and there is at least one answer\n",
    "                if len(qa['answers']) > 0 and not(qa['is_impossible']):\n",
    "\n",
    "                    # Create the question/context sequence\n",
    "                    question_context = 'question: ' + qa['question'] + ' context: ' + context\n",
    "\n",
    "                    # Create the answer sequence. Use the text field of the first answer\n",
    "                    answer = 'answer: ' + qa['answers'][0]['text']\n",
    "\n",
    "                    # Add the question_context to the inputs list\n",
    "                    inputs.append(question_context)\n",
    "\n",
    "                    # Add the answer to the targets list\n",
    "                    targets.append(answer)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return inputs, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7ddde263-4b51-4feb-a028-3ab2d98a32b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1743250614122,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "7ddde263-4b51-4feb-a028-3ab2d98a32b8",
    "outputId": "73e18b43-31ee-4a6f-d6b8-7f24c496d16e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of question/answer pairs: 86821\n",
      "\n",
      "First Q/A pair:\n",
      "\n",
      "inputs: \u001b[34mquestion: When did Beyonce start becoming popular? context: Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\u001b[0m\n",
      "\n",
      "targets: \u001b[32manswer: in the late 1990s\u001b[0m\n",
      "\n",
      "Last Q/A pair:\n",
      "\n",
      "inputs: \u001b[34mquestion: What is KMC an initialism of? context: Kathmandu Metropolitan City (KMC), in order to promote international relations has established an International Relations Secretariat (IRC). KMC's first international relationship was established in 1975 with the city of Eugene, Oregon, United States. This activity has been further enhanced by establishing formal relationships with 8 other cities: Motsumoto City of Japan, Rochester of the USA, Yangon (formerly Rangoon) of Myanmar, Xi'an of the People's Republic of China, Minsk of Belarus, and Pyongyang of the Democratic Republic of Korea. KMC's constant endeavor is to enhance its interaction with SAARC countries, other International agencies and many other major cities of the world to achieve better urban management and developmental programs for Kathmandu.\u001b[0m\n",
      "\n",
      "targets: \u001b[32manswer: Kathmandu Metropolitan City\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "inputs, targets =  parse_squad(example_jsons)\n",
    "print(\"Number of question/answer pairs: \" + str(len(inputs)))\n",
    "\n",
    "print('\\nFirst Q/A pair:\\n\\ninputs: ' + colored(inputs[0], 'blue'))\n",
    "print('\\ntargets: ' + colored(targets[0], 'green'))\n",
    "print('\\nLast Q/A pair:\\n\\ninputs: ' + colored(inputs[-1], 'blue'))\n",
    "print('\\ntargets: ' + colored(targets[-1], 'green'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce986da8-7027-46f0-91ae-62feb9b82e4c",
   "metadata": {
    "id": "ce986da8-7027-46f0-91ae-62feb9b82e4c"
   },
   "source": [
    "#### **Expected Output:**\n",
    "```\n",
    "Number of question/answer pairs: 86821\n",
    "\n",
    "First Q/A pair:\n",
    "\n",
    "inputs: question: When did Beyonce start becoming popular? context: Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n",
    "\n",
    "targets: answer: in the late 1990s\n",
    "\n",
    "Last Q/A pair:\n",
    "\n",
    "inputs: question: What is KMC an initialism of? context: Kathmandu Metropolitan City (KMC), in order to promote international relations has established an International Relations Secretariat (IRC). KMC's first international relationship was established in 1975 with the city of Eugene, Oregon, United States. This activity has been further enhanced by establishing formal relationships with 8 other cities: Motsumoto City of Japan, Rochester of the USA, Yangon (formerly Rangoon) of Myanmar, Xi'an of the People's Republic of China, Minsk of Belarus, and Pyongyang of the Democratic Republic of Korea. KMC's constant endeavor is to enhance its interaction with SAARC countries, other International agencies and many other major cities of the world to achieve better urban management and developmental programs for Kathmandu.\n",
    "\n",
    "targets: answer: Kathmandu Metropolitan City\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd6cd04-4910-45a9-b066-01a4db03dd9b",
   "metadata": {
    "id": "3bd6cd04-4910-45a9-b066-01a4db03dd9b"
   },
   "source": [
    "We'll use 50000 samples for training and 5000 samples for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa66e90a-a22e-4de4-bb70-8a054a2c123e",
   "metadata": {},
   "source": [
    "### Creating Train and Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "66cebe06-7b68-46fb-95d5-3c14dab50468",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1743250617687,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "66cebe06-7b68-46fb-95d5-3c14dab50468"
   },
   "outputs": [],
   "source": [
    "# 50K pairs for training\n",
    "inputs_train = inputs[0:40000]\n",
    "targets_train = targets[0:40000]\n",
    "\n",
    "# 5K pairs for testing\n",
    "inputs_test = inputs[40000:45000]\n",
    "targets_test =  targets[40000:45000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b420eed-1d33-4d71-91ad-2e3519db6eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f00fbdb8-fbd8-441b-8eee-48ab3dcaf144",
   "metadata": {},
   "source": [
    "# **Fine-Tuning Section Part-2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55d5315-cef9-489d-b833-6c5d70c278e8",
   "metadata": {
    "id": "c55d5315-cef9-489d-b833-6c5d70c278e8"
   },
   "source": [
    "## Setting up Dataloader\n",
    "Now, we can create the batch dataset of padded sequences. We'll first tokenize the inputs and the targets. Then, we'll ensure that the inputs and the outputs have the required lengths. Remember that the sequences longer than the required size will be truncated and the shorter ones will be padded with `0`. This setup is very similar to the other one used previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3b18fa93-6c8d-437e-b5bf-97d7ad9525f8",
   "metadata": {
    "executionInfo": {
     "elapsed": 8404,
     "status": "ok",
     "timestamp": 1743254167956,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "3b18fa93-6c8d-437e-b5bf-97d7ad9525f8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Hyperparameters\n",
    "encoder_maxlen = 150\n",
    "decoder_maxlen = 50\n",
    "BATCH_SIZE     = 64\n",
    "\n",
    "# EOS token id (usually 1 for SentencePiece)\n",
    "eos_id = 1\n",
    "\n",
    "# Tokenize inputs\n",
    "inputs_str = [tokenizer.encode(s, out_type=int) for s in inputs_train]\n",
    "\n",
    "# Tokenize targets and add EOS token\n",
    "targets_str = [tokenizer.encode(s, out_type=int) + [eos_id] for s in targets_train]\n",
    "\n",
    "# Padding function\n",
    "def pad_sequences(sequences, maxlen, pad_value=0):\n",
    "    return np.array([\n",
    "        seq[:maxlen] + [pad_value] * max(0, maxlen - len(seq))\n",
    "        for seq in sequences\n",
    "    ])\n",
    "\n",
    "# Pad inputs and targets\n",
    "inputs_padded  = pad_sequences(inputs_str, encoder_maxlen)\n",
    "targets_padded = pad_sequences(targets_str, decoder_maxlen)\n",
    "\n",
    "# Convert to torch tensors\n",
    "inputs_tensor  = torch.tensor(inputs_padded, dtype=torch.long)\n",
    "targets_tensor = torch.tensor(targets_padded, dtype=torch.long)\n",
    "\n",
    "# Create PyTorch dataset and dataloader\n",
    "dataset    = TensorDataset(inputs_tensor, targets_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4eb3636-297b-41fd-a93d-2bd618549fc4",
   "metadata": {},
   "source": [
    "# Skip the following cells until you reach the one labeled \"skip_end!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "011c071f-9518-4efe-814a-11d46aa735f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1743254167997,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "011c071f-9518-4efe-814a-11d46aa735f2",
    "outputId": "5c6a0444-50dd-4c91-9ddc-b63a32fe21e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 150]), torch.Size([64, 50]))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for (batch, (inp, tar)) in enumerate(dataloader):\n",
    "    if batch >=2:\n",
    "        break\n",
    "inp.shape, tar.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "52e5019e-7237-4485-8c42-655a73176e19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1743250630293,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "52e5019e-7237-4485-8c42-655a73176e19",
    "outputId": "472557c8-c305-467b-bcf9-6935927677c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 822,   10,  571,  ...,    5,   37,  167],\n",
       "        [ 822,   10,  363,  ...,    0,    0,    0],\n",
       "        [ 822,   10,  363,  ...,   31,    7, 3251],\n",
       "        ...,\n",
       "        [ 822,   10,   37,  ...,  892,    5,    0],\n",
       "        [ 822,   10,  366,  ...,   33,   59,  347],\n",
       "        [ 822,   10,  363,  ..., 6982, 5752,  120]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "16c0e24b-1dc2-4e80-ab36-478b93f2bb9b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1743250630302,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "16c0e24b-1dc2-4e80-ab36-478b93f2bb9b",
    "outputId": "44eeec3d-d6bc-404e-fcd2-10507c2697cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  822,    10,   363,  1440,    43,   600,   452,  8981,    68,   731,\n",
       "        13100,    58,  2625,    10,  1881,   324,     7,   757,    11,  2399,\n",
       "          452,  2887,    19,     6,    16,  1402,     6,    16, 29112,    44,\n",
       "         1020,    13,     3, 18036,    63,   159,    51,     6,  4583,  1549,\n",
       "            7,     6,    11, 10960,    15, 15133,   297,     5,  4961, 26221,\n",
       "           26,  4750,    11,     3, 26968,     6,    73, 23313,  2314,  3498,\n",
       "            3, 31488,     8,   682,     5,   100,    19,    80,  5464,    21,\n",
       "        11596,  1707,    11,    20, 27522,     5,  4495,  9977,     7,    13,\n",
       "        11596,  1707,   217,     8,  5464,    38, 30981,     5,    37,  5464,\n",
       "           24, 13100,  6539,  6963,    45,     8,  1004,    19,     3, 31315,\n",
       "           57,     8,  6831,    13,  1440,    28,   731,    12,   529,    18,\n",
       "        13957, 13100,    68,   508,   452,  8981,     6,   114,     8, 24207,\n",
       "         1440,     5,   506,  1440,  2604,   306,    30,     8,   262,     9,\n",
       "            7,    15,    13,   531,    53,  1769, 11507,     6,   788,    12,\n",
       "          207,    11,   557,   650,  4750,     6,    11,    43,  3356,    13])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp[5,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e5f41a66-7635-4ceb-ace1-be38e56caf66",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1743250631739,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "e5f41a66-7635-4ceb-ace1-be38e56caf66",
    "outputId": "3a56b0f3-d98e-418b-85e9-586ff932136a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  822,    10,   363,    19, 18908,    57,     8,  3053,    13,     3,\n",
       "          476,  1626,  7379, 10739,   445,    58,  2625,    10,  1908,  2528,\n",
       "            7,    33, 18908,    57,     8,  3053,    13,     3,   476,  1626,\n",
       "         7379, 10739,   445,   859,   135,     5,  1844,    83,   920,    12,\n",
       "        26843,    45, 26181,  3826,     6,    34,    19,   435,    44,   306,\n",
       "         1917,    16,  4575,     9,  2176,   151,     7,     5,    94,     7,\n",
       "         3053,    16,  1908,  2528,     7,    41,  9341,    96, 22969,    49,\n",
       "           29,  4263,     7,   121,    16,     8,   934,    61,    44,  4377,\n",
       "            7,    12,     8,   529,    18,   134,   521,  7287, 14430,     7,\n",
       "           41, 13682,    53,    28, 22896,   447, 14430,     7,    13,  8390,\n",
       "         4491, 19867,     9,   137,  2040, 10348,  1427,     6,  4263,     7,\n",
       "           33,  2389,  1126,    12, 11683,    16,  2069,    18,    15,     9,\n",
       "        13072,  1740,    68,   128,  8390,  4263,     7,    33, 18957,    12,\n",
       "        22896,    32,    18,  1265,  3496,    75,  1637,     5,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp[1,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f4d153b0-3690-4365-917d-05c9957a84f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1743250633405,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "f4d153b0-3690-4365-917d-05c9957a84f6",
    "outputId": "95b5f390-92b5-438c-a3f2-ee647feff438"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'▁question'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.id_to_piece(822)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "faf68a5c-fea5-49df-8b99-c28274fd8353",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 295,
     "status": "ok",
     "timestamp": 1743250634108,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "faf68a5c-fea5-49df-8b99-c28274fd8353",
    "outputId": "6aaf0170-049f-490a-d949-596cacdd4689"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.id_to_piece(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "312d2ec3-92c8-43f7-8c7a-f260b68d6ef2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1743250634282,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "312d2ec3-92c8-43f7-8c7a-f260b68d6ef2",
    "outputId": "275a19b6-d32e-4c67-d2f8-b7c5e650bc34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1525,    10, 24207,     1,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar[5,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cb4d3787-d43a-478d-98ec-d8edfeb894f8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1743250635437,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "cb4d3787-d43a-478d-98ec-d8edfeb894f8",
    "outputId": "5917bacb-cf07-46a6-9d64-3944057259b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1525,   10, 1908, 2528,    7,    1,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar[1,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "14b8e35a-ca27-4a55-a864-dfed159a3e29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 237,
     "status": "ok",
     "timestamp": 1743250635988,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "14b8e35a-ca27-4a55-a864-dfed159a3e29",
    "outputId": "f4e9bb62-b58e-4258-d6d7-f44995019c2c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'▁answer'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.id_to_piece(1525)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "00c6faf2-5cf5-46cb-9dda-b8e72ad45984",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1743250636084,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "00c6faf2-5cf5-46cb-9dda-b8e72ad45984",
    "outputId": "b8ab6b21-51c5-4d41-90e6-f0703a3fe6e7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'question: What countries have big public sectors but low corruption? context: Extensive and diverse public spending is, in itself, inherently at risk of cronyism, kickbacks, and embezzlement. Complicated regulations and arbitrary, unsupervised official conduct exacerbate the problem. This is one argument for privatization and deregulation. Opponents of privatization see the argument as ideological. The argument that corruption necessarily follows from the opportunity is weakened by the existence of countries with low to non-existent corruption but large public sectors, like the Nordic countries. These countries score high on the Ease of Doing Business Index, due to good and often simple regulations, and have rule of'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.detokenize(inp[5,:].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cf533a85-e208-4fd7-b102-859298a89dfc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1743250637265,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "cf533a85-e208-4fd7-b102-859298a89dfc",
    "outputId": "e0a88d17-8288-4652-8f0b-f1a5196272ec"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'answer: Nordic'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.detokenize(tar[5,:].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6bfc128e-2642-414b-a111-a0baf89a83eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1743250639184,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "6bfc128e-2642-414b-a111-a0baf89a83eb",
    "outputId": "e1550725-eb00-428e-d944-d64d96593f5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "625"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1ee4a9-695d-46ee-9bb0-291f45195ab7",
   "metadata": {},
   "source": [
    "# skip_end!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e6f7d7-8097-4939-81c0-4acb133d4a24",
   "metadata": {
    "id": "e8e6f7d7-8097-4939-81c0-4acb133d4a24"
   },
   "source": [
    "## Training Loop\n",
    "\n",
    "Now, we'll train the model for 2 epochs. In the T5 model, all the weights are adjusted during the fine tuning. As usual, fine tuning this model to get state of the art results would require more time and resources than there are available in this environment, but you are welcome to train the model for more epochs and with more data using Colab GPUs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62548e5b-eb56-4d7d-b01d-31db28cb00ae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 181006,
     "status": "error",
     "timestamp": 1743254834247,
     "user": {
      "displayName": "Ans Imran",
      "userId": "16137081719601513890"
     },
     "user_tz": -60
    },
    "id": "62548e5b-eb56-4d7d-b01d-31db28cb00ae",
    "outputId": "499e580f-2dc7-4a89-ad50-ba757050de19",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch import save\n",
    "from torch.amp import GradScaler, autocast\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.nn import NLLLoss\n",
    "from torch.optim import AdamW\n",
    "import time\n",
    "\n",
    "# Move model to device\n",
    "transformer.to(device_)\n",
    "\n",
    "# Loss, optimizer, scaler\n",
    "pad_idx       = 0                              # Padding index to ignore in loss calculation\n",
    "learning_rate = 1e-3                           # Learning rate for optimizer\n",
    "num_epochs    = 100                            # Total number of training epochs\n",
    "\n",
    "criterion = NLLLoss(ignore_index=pad_idx)      # Negative log-likelihood loss, ignoring pad tokens\n",
    "optimizer = AdamW(transformer.parameters(), lr=learning_rate)  # AdamW optimizer for weight decay\n",
    "scaler    = GradScaler()                       # Gradient scaler for mixed precision training\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'\\nEpoch [{epoch + 1}/{num_epochs}]')\n",
    "    start_time = time.time()\n",
    "\n",
    "    transformer.train()                                   # Set model to training mode\n",
    "    running_loss = 0\n",
    "\n",
    "    for batch_idx, (inp, tar) in enumerate(dataloader):\n",
    "        inp = inp.to(device_, non_blocking=True)          # Move input to device asynchronously\n",
    "        tar = tar.to(device_, non_blocking=True)          # Move target to device asynchronously\n",
    "\n",
    "        optimizer.zero_grad()                             # Zero out previous gradients\n",
    "\n",
    "        with autocast(device_type=device_.type):          # Enable autocasting for mixed precision\n",
    "            preds, _ = transformer(inp, tar[:, :-1])      # Forward pass with input and target excluding last token\n",
    "            outputs  = preds.reshape(-1, preds.shape[2])  # Flatten output for loss calculation\n",
    "            targets  = tar[:, 1:].reshape(-1)             # Flatten shifted targets\n",
    "            loss     = criterion(outputs, targets)        # Compute loss\n",
    "\n",
    "        scaler.scale(loss).backward()                     # Backprop with scaled loss\n",
    "        clip_grad_norm_(transformer.parameters(), max_norm=1.0)  # Gradient clipping to stabilize training\n",
    "        scaler.step(optimizer)                            # Optimizer step with scaler\n",
    "        scaler.update()                                   # Update scaler for next iteration\n",
    "\n",
    "        running_loss += loss.item()                       # Accumulate loss\n",
    "        avg_loss      = running_loss / (batch_idx + 1)    # Compute average loss\n",
    "\n",
    "        if (batch_idx + 1) % 20 == 0:                     # Print loss every 20 batches\n",
    "            print(f\"[Batch {batch_idx + 1}/{len(dataloader)}] Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    epoch_time = time.time() - start_time\n",
    "    print(f\"Epoch Time: {epoch_time:.2f}s | Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Evaluation: Top-k prediction on an eval example\n",
    "    transformer.eval()                                                              # Set model to evaluation mode\n",
    "    with torch.no_grad():                                                           # Disable gradient computation\n",
    "        eval_preds, _   = transformer(eval_inp, eval_tar_inp)                       # Get predictions on evaluation input\n",
    "        _, topk_indices = torch.topk(eval_preds[:, -1, :], k=10, dim=-1)            # Top-10 predictions on last token\n",
    "        topk_indices    = topk_indices.to('cpu').int().tolist()                     # Move to CPU and convert to list\n",
    "        decoded_answers = [tokenizer.detokenize([idx]) for idx in topk_indices[0]]  # Decode predictions\n",
    "\n",
    "        print(f\"\\n[Eval Example]:\\n{example_question}\")                             # Print example input\n",
    "        print(f\"Top 10 Predictions: {decoded_answers}\\n\")                           # Print top-10 predicted answers\n",
    "\n",
    "    # Save the model (you can customize path)\n",
    "#    SAVE_PATH = f\"transformer_epoch_{epoch + 1}.pt\"                                # Optional: define save path per epoch\n",
    "    torch.save({\n",
    "                'epoch':                epoch,                                      # Save current epoch\n",
    "                'model_state_dict':     transformer.state_dict(),                   # Save model parameters\n",
    "                'optimizer_state_dict': optimizer.state_dict(),                     # Save optimizer state\n",
    "                'scaler_state_dict':    scaler.state_dict(),                        # Save AMP scaler state\n",
    "                'loss':                 avg_loss                                    # Save loss for reference\n",
    "                },\n",
    "        os.path.join(SAVE_PATH, f'checkpoint_epoch_{epoch+1}.pt'))                  # Save to checkpoint file\n",
    "\n",
    "#    save({'model_state_dict': transformer.state_dict()}, save_path)                # Optional save using shorthand\n",
    "    print(f\"Model saved to {SAVE_PATH}\")                                            # Confirm save location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fe64e6-8590-4cab-867b-ea457fa13ad4",
   "metadata": {
    "id": "15fe64e6-8590-4cab-867b-ea457fa13ad4"
   },
   "outputs": [],
   "source": [
    "# code for saving and loading the model\n",
    "\n",
    "# import torch\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "# torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "\n",
    "# torch.save({\n",
    "#     'epoch': epoch,\n",
    "#     'model_state_dict': transformer.state_dict(),\n",
    "#     'optimizer_state_dict': optimizer.state_dict(),\n",
    "#     'scaler_state_dict': scaler.state_dict(),  # If using AMP\n",
    "#     'loss': avg_loss\n",
    "# }, os.path.join(SAVE_PATH, f'checkpoint_epoch_{epoch+1}.pt'))\n",
    "\n",
    "\n",
    "# checkpoint = torch.load('your checkpoint', map_location=device_)\n",
    "\n",
    "# transformer.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# scaler.load_state_dict(checkpoint['scaler_state_dict'])  # Only if you're using AMP\n",
    "\n",
    "# start_epoch = checkpoint['epoch'] + 1\n",
    "# transformer.to(device_)\n",
    "# transformer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60982a94-fee1-4bb7-96e4-83b40b3c0a43",
   "metadata": {
    "id": "60982a94-fee1-4bb7-96e4-83b40b3c0a43"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a09720-c792-4ce6-ab46-832a56ee3f57",
   "metadata": {
    "id": "01a09720-c792-4ce6-ab46-832a56ee3f57"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9e5d8b2-c6f6-451f-ba8a-23b5256898c5",
   "metadata": {
    "id": "e9e5d8b2-c6f6-451f-ba8a-23b5256898c5"
   },
   "source": [
    "To get a model that works properly, we would need to train for about 100 epochs. So, we have pretrained a model. Just loading the weights in the current model and let's use it for answering questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fde7d1-5524-4afb-8232-f542045c6e1c",
   "metadata": {
    "id": "92fde7d1-5524-4afb-8232-f542045c6e1c"
   },
   "source": [
    "# Inference\n",
    "\n",
    "In this final step, you will implement the answer_question function, utilizing a pre-trained transformer model for question answering.\n",
    "\n",
    "To help you out the `transformer_utils.next_word` function is provided. This function receives the question and beginning of the answer (both in tensor format) alongside the model to predict the next token in the answer. The next cell shows how to use this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "qcrESG--F-Yi",
   "metadata": {
    "id": "qcrESG--F-Yi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import load\n",
    "from torch import device, tensor\n",
    "device_ = device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "path       = 'best_qA_model.pt'\n",
    "checkpoint = load(path, map_location=device_, weights_only=True)\n",
    "transformer.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9ad0d747-5d16-4c17-96a7-284ce7de70df",
   "metadata": {
    "id": "9ad0d747-5d16-4c17-96a7-284ce7de70df"
   },
   "outputs": [],
   "source": [
    "# # Define an example question and context\n",
    "# example_question = \"question: What color is the sky? context: Sky is blue.\"\n",
    "# example_tar     = 'answer: '\n",
    "\n",
    "# example_question = \"question: What is the color of his shirt? context: His boots are red. His pants are orange. His shirt is pink. His hair are yellow\"\n",
    "# example_question = \"question: Where is he sitting? context: He is sitting on a chair\"\n",
    "\n",
    "example_question = \"question: When did Beyonce start becoming popular? context: Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles Crazy in Love and Baby Boy\"\n",
    "example_tar     = 'answer: '\n",
    "# example_question = \"question: What color is the sky? context: Sky is blue answer: blue. question: What color is his shirt? context: His shirt is yellow. answer: yellow. question: what color is his bike? context: His bike is red.\"\n",
    "# example_tar     = 'answer: '\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b0817c43-44fb-45f4-bd98-c71f0073528b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "# Creating Inputs\n",
    "\n",
    "eval_inp     = example_question\n",
    "eval_tar_inp = 'answer: '\n",
    "\n",
    "eval_inp     = tokenizer.tokenize(eval_inp)\n",
    "eval_tar_inp = tokenizer.tokenize(eval_tar_inp)\n",
    "\n",
    "eval_inp     = torch.tensor(eval_inp, dtype=torch.long, device=device_)\n",
    "eval_tar_inp = torch.tensor(eval_tar_inp, dtype=torch.long, device=device_)\n",
    "\n",
    "eval_inp     = eval_inp.unsqueeze(0)\n",
    "eval_tar_inp = eval_tar_inp.unsqueeze(0)\n",
    "\n",
    "transformer.to(device_)\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "af4ef065-561a-4303-9f56-d6198b3b9ae7",
   "metadata": {
    "id": "af4ef065-561a-4303-9f56-d6198b3b9ae7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Eval Example]:\n",
      "question: When did Beyonce start becoming popular? context: Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles Crazy in Love and Baby Boy\n",
      "Top 10 Predictions: ['July', '2014', 'November', 'late', '1977', 'June', '2003', 'September', '1990', '2013']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting Predictions and Printing Them Out | On Training Data | See Deployment Snapshots for results on unseen data\n",
    "transformer.eval()\n",
    "with torch.no_grad():\n",
    "    eval_preds, _   = transformer(eval_inp, eval_tar_inp)\n",
    "    _, topk_indices = torch.topk(eval_preds[:, -1, :], k=10, dim=-1)\n",
    "    topk_indices    = topk_indices.int().tolist()\n",
    "    decoded_answers = [tokenizer.detokenize([idx]) for idx in topk_indices[0]]\n",
    "\n",
    "    print(f\"\\n[Eval Example]:\\n{example_question}\")\n",
    "    print(f\"Top 10 Predictions: {decoded_answers}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9f1722-0fe0-46b9-93ee-4721b447853d",
   "metadata": {},
   "source": [
    "**The correct answer given the context is \"late 1990\". We observe that both of these tokens appear in the model's top-10 predictions, indicating that the model is indeed learning and our setup is working as intended!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "75804c31-faa6-492c-ade4-0673e15b4253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save({'model_state_dict': transformer.state_dict()}, 'best_qA_model.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767d544d-f5a7-426d-ae26-f9b1834b9114",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086d92d7-f5b0-4dca-b237-1b040c831d6b",
   "metadata": {},
   "source": [
    "In this notebook, we pretrained our model for approximately 100 epochs. To evaluate the effectiveness of this pretraining, we conducted two experiments:\n",
    "\n",
    "1. **Fine-tuning a pretrained model**: The pretrained model started yielding promising results within just 3–4 epochs of fine-tuning.\n",
    "2. **Training an uninitialized (randomly initialized) model**: In contrast, the untrained model required around 60 epochs to achieve similar performance.\n",
    "\n",
    "This clearly indicates that pretraining was effective and significantly accelerated convergence during fine-tuning.\n",
    "\n",
    "During inference, we passed questions along with contextual information to the model. We observed that the pretrained and fine-tuned model was often able to return the correct answer — or something close — within its top-10 (Top-K) predictions. For example, when asked:\n",
    "\n",
    "> *\"What color is the sky?\"*  \n",
    "> *Context: \"The sky is blue.\"*\n",
    "\n",
    "At later stages of pretraining, the model frequently returned tokens like `\"color\"`, `\"black\"`, `\"blue\"`, and `\"red\"` — showing that it was learning meaningful representations. In contrast, earlier in training, its predictions were much less relevant.\n",
    "\n",
    "Interestingly, right after pretraining, the model began producing good results within 4–5 epochs of fine-tuning, but then its performance declined — the correct answers were no longer within the top-10 predictions. It wasn’t until around epoch 80–90 that it began recovering and producing even better results than before. This behavior suggests potential **catastrophic forgetting** during full fine-tuning.\n",
    "\n",
    "---\n",
    "\n",
    "### What’s Next\n",
    "\n",
    "To mitigate this issue in future experiments, we plan to explore **parameter-efficient fine-tuning** methods such as **LoRA** or **QLoRA**. These approaches could help preserve the model's pretrained knowledge while still adapting it effectively to downstream tasks.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
